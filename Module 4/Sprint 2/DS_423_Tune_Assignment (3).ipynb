{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "\n",
        "\n",
        "# Hyperparameter Tuning Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "# Gridsearch Hyperparameters\n",
        "\n",
        "In the guided project, you learned how to use sklearn's `GridsearchCV` and `keras-tuner` libraries to tune the hyperparameters of a neural network model. For your module project you'll continue using these two libraries, however we are going to make things a little more interesting for you. \n",
        "\n",
        "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. \n",
        "\n",
        "\n",
        "\n",
        "**Don't forget to switch to GPU on Colab!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7oEgGCV3_hY"
      },
      "source": [
        "## 0.1 Imports and installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxctNMPb7mNY",
        "outputId": "7ae83304-2e15-4095-c3e2-dec49018a424"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Logan\\AppData\\Local\\Temp/ipykernel_17212/2169646595.py:26: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  import kerastuner\n"
          ]
        }
      ],
      "source": [
        "# native python libraries imports \n",
        "import math\n",
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# sklearn imports \n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# keras imports \n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.activations import relu, sigmoid\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "# required for compatibility between sklearn and keras\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# install keras-tuner\n",
        "\n",
        "import kerastuner\n",
        "from kerastuner.tuners import RandomSearch, BayesianOptimization, Sklearn\n",
        "from kerastuner.engine.hyperparameters import HyperParameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMBS8CRBzYqB"
      },
      "source": [
        "## 0.2 Load quickdraw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kr8w6IX37mNa"
      },
      "outputs": [],
      "source": [
        "def load_quickdraw10():\n",
        "    \"\"\"\n",
        "    Fill out this doc string, and comment the code, for practice in writing the kind of code that will get you hired. \n",
        "    \"\"\"\n",
        "    \n",
        "    URL_ = \"https://github.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\"\n",
        "    \n",
        "    path_to_zip = get_file('./quickdraw10.npz', origin=URL_, extract=False)\n",
        "\n",
        "    data = np.load(path_to_zip)\n",
        "    \n",
        "    # normalize your image data\n",
        "    max_pixel_value = 255\n",
        "    X = data['arr_0']/max_pixel_value\n",
        "    Y = data['arr_1']\n",
        "        \n",
        "    return train_test_split(X, Y, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjU5nY3e7mNc"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = load_quickdraw10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkvBPoUy7mNd",
        "outputId": "df54d06e-52c1-463f-957c-19a133ae0cc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(75000, 784)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4dx6VA07mNe",
        "outputId": "a0871366-9716-40a4-95fa-f3783242a9ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(75000,)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXsWtj8Z7mNf"
      },
      "source": [
        "_____\n",
        "\n",
        "# Experiment 1\n",
        "\n",
        "## Tune Hyperperameters using Enhanced GridsearchCV \n",
        "\n",
        "We are going to use GridsearchCV again to tune a deep learning model however we are going to add some additional functionality to our gridsearch. \n",
        "\n",
        "Specifically, we are going to automate the generation of how many nodes to use in a layer and how many layers to use in a model! \n",
        "\n",
        "By the way, yes, there is a function within a function. Try to not let that bother you. An alternative to this would be to create a class. If you're up for the challenge give it a shot. However, consider this a stretch goal that you come back to after you finish going through this assignment. \n",
        "\n",
        "\n",
        "### Objective \n",
        "\n",
        "The objective of this experiment is to show you how to automate the generation of layers and layer nodes for the purposes of gridsearch. <br>\n",
        "Up until now, we've been manually selecting the number of layers and layer nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USXjs7Hk71Hy"
      },
      "outputs": [],
      "source": [
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(n_layers,  first_layer_nodes, last_layer_nodes, act_funct =\"relu\", negative_node_incrementation=True):\n",
        "    \"\"\"\"\n",
        "    Returns a compiled keras model \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    n_layers: int \n",
        "        number of hidden layers in model \n",
        "        To be clear, this excludes the input and output layer.\n",
        "        \n",
        "    first_layer_nodes: int\n",
        "        Number of nodes in the first hidden layer \n",
        "\n",
        "    last_layer_nodes: int\n",
        "        Number of nodes in the last hidden layer (this is the layer just prior to the output layer)\n",
        "        \n",
        "     act_funct: string \n",
        "         Name of activation function to use in hidden layers (this excludes the output layer)\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    model: keras object \n",
        "    \"\"\"\n",
        "    \n",
        "    def gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation=True):\n",
        "        \"\"\"\n",
        "        Generates and returns the number of nodes in each hidden layer. \n",
        "        To be clear, this excludes the input and output layer. \n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        Number of nodes in each layer is linearly incremented. \n",
        "        For example, gen_layer_nodes(5, 500, 100) will generate [500, 400, 300, 200, 100]\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_layers: int\n",
        "            Number of hidden layers\n",
        "            This values should be 2 or greater \n",
        "\n",
        "        first_layer_nodes: int\n",
        "\n",
        "        last_layer_nodes: int\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        layers: list of ints\n",
        "            Contains number of nodes for each layer \n",
        "        \"\"\"\n",
        "\n",
        "        # throws an error if n_layers is less than 2 \n",
        "        assert n_layers >= 2, \"n_layers must be 2 or greater\"\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        # PROTIP: IF YOU WANT THE NODE INCREMENTATION TO BE SPACED DIFFERENTLY\n",
        "        # THEN YOU'LL NEED TO CHANGE THE WAY THAT IT'S CALCULATED - HAVE FUN!\n",
        "        # when set to True number of nodes are decreased for subsequent layers \n",
        "        # NOTE: the order of the number of nodes doesn't matter\n",
        "        if negative_node_incrementation:\n",
        "            # subtract this amount from previous layer's nodes in order to increment towards smaller numbers \n",
        "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
        "            \n",
        "        # when set to False number of nodes are increased for subsequent layers\n",
        "        else:\n",
        "            # add this amount from previous layer's nodes in order to increment towards larger numbers \n",
        "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
        "\n",
        "        nodes = first_layer_nodes\n",
        "\n",
        "        for i in range(1, n_layers+1):\n",
        "\n",
        "            layers.append(math.ceil(nodes))\n",
        "\n",
        "            # increment nodes for next layer \n",
        "            nodes = nodes + nodes_increment\n",
        "\n",
        "        return layers\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
        "    \n",
        "    for i in range(1, n_layers):\n",
        "        if i==1:\n",
        "            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=act_funct))\n",
        "        else:\n",
        "            model.add(Dense(n_nodes[i-1], activation=act_funct))\n",
        "            \n",
        "            \n",
        "    # output layer \n",
        "    model.add(Dense(10, # 10 unit/neurons in output layer because we have 10 possible labels to predict  \n",
        "                    activation='softmax')) # use softmax for a label set greater than 2            \n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(loss='sparse_categorical_crossentropy', \n",
        "                  optimizer='adam', # adam is a good default optimizer \n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # do not include model.fit() inside the create_model function\n",
        "    # KerasClassifier is expecting a complied model \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO-x0nqt7mNh"
      },
      "source": [
        "## 1.1 Explore `create_model`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1hnjQHKW19w"
      },
      "source": [
        "The helper function `gen_layer_nodes()` which is contained inside `create_model()` <br>\n",
        "returns a list containing the number of nodes for each successive layer.<br>\n",
        "\n",
        "Let's check that `gen_layer_nodes()` behaves as expected. <br>\n",
        "In other words, we'll perform a **Unit Test!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiPXu0p_Qco_"
      },
      "outputs": [],
      "source": [
        "    def gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation=True):\n",
        "        \"\"\"\n",
        "        Generates and returns the number of nodes in each hidden layer. \n",
        "        To be clear, this excludes the input and output layer. \n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        Number of nodes in each layer is linearly incremented. \n",
        "        For example, gen_layer_nodes(5, 500, 100) will generate [500, 400, 300, 200, 100]\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_layers: int\n",
        "            Number of hidden layers\n",
        "            This values should be 2 or greater \n",
        "\n",
        "        first_layer_nodes: int\n",
        "\n",
        "        last_layer_nodes: int\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        layers: list of ints\n",
        "            Contains number of nodes for each layer \n",
        "        \"\"\"\n",
        "\n",
        "        # throws an error if n_layers is less than 2 \n",
        "        assert n_layers >= 2, \"n_layers must be 2 or greater\"\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        # PROTIP: IF YOU WANT THE NODE INCREMENTATION TO BE SPACED DIFFERENTLY\n",
        "        # THEN YOU'LL NEED TO CHANGE THE WAY THAT IT'S CALCULATED - HAVE FUN!\n",
        "        # when set to True number of nodes are decreased for subsequent layers \n",
        "        # NOTE: the order of the number of nodes doesn't matter\n",
        "        if negative_node_incrementation:\n",
        "            # subtract this amount from previous layer's nodes in order to increment towards smaller numbers \n",
        "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
        "            #print(f'nodes increment = {nodes_increment}')\n",
        "            \n",
        "        # when set to False number of nodes are increased for subsequent layers\n",
        "        else:\n",
        "            # add this amount from previous layer's nodes in order to increment towards larger numbers \n",
        "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
        "            #print(f'nodes increment = {nodes_increment}')\n",
        "\n",
        "        nodes = first_layer_nodes\n",
        "\n",
        "        for i in range(1, n_layers+1):\n",
        "\n",
        "            layers.append(math.ceil(nodes))\n",
        "\n",
        "            # increment nodes for next layer \n",
        "            nodes = nodes + nodes_increment\n",
        "\n",
        "        return layers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj3MrB6jXUMG"
      },
      "source": [
        "### `negative_node_incrementation = True`\n",
        "For this case we want the number of nodes to _decrease_ by a constant number for successive layers. <br>So `first_layer_nodes` must be _larger_ than `last_layer_nodes` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m4jRNllXPPG",
        "outputId": "e30bda1b-658e-40c9-8a74-dc228e6055b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes in successive layers: [500, 400, 300, 200, 100]\n"
          ]
        }
      ],
      "source": [
        "n_layers = 5\n",
        "first_layer_nodes = 500\n",
        "last_layer_nodes = 100\n",
        "negative_node_incrementation = True\n",
        "n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
        "print(f'Number of nodes in successive layers: {n_nodes}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttkaf3g9XhGr"
      },
      "source": [
        "### `negative_node_incrementation = False`\n",
        "For this case we want the number of nodes to _increase_ by a constant number for successive layers. <br>So `first_layer_nodes` must be _smaller_ than `last_layer_nodes` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fkrMS8bXQUo",
        "outputId": "e7f849a8-831c-45b7-98f1-d369eb32a86b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes in successive layers: [100, 200, 300, 400, 500]\n"
          ]
        }
      ],
      "source": [
        "n_layers = 5\n",
        "first_layer_nodes = 100\n",
        "last_layer_nodes = 500\n",
        "negative_node_incrementation = False\n",
        "n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
        "print(f'Number of nodes in successive layers: {n_nodes}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHuB-bm5Wkpq"
      },
      "source": [
        "### OK, the Unit Test is passed!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO3AjVWOZ6SA"
      },
      "source": [
        "### Let's build a few models<br> \n",
        "in order to understand how `create_model()` works in practice. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95E85Ug07mNh"
      },
      "source": [
        "### Build a model, setting `negative_node_incrementation = True` \n",
        "\n",
        "Use `create_model` to build a model. \n",
        "\n",
        "- Set `n_layers = 10` \n",
        "- Set `first_layer_nodes = 500`\n",
        "- Set `last_layer_nodes = 100`\n",
        "- Set `act_funct = \"relu\"`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "x_1REOCY7mNi",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5dcf5c585f07629a03086cf57ba53615",
          "grade": false,
          "grade_id": "cell-86d63e89a21223de",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# use create_model to create a model \n",
        "\n",
        "# YOUR CODE HERE\n",
        "model = create_model(n_layers=10, first_layer_nodes=500, last_layer_nodes=100, negative_node_incrementation=True,act_funct='relu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYMwZQ7k7mNi",
        "outputId": "bbf50461-dddd-4b41-f5cc-76b41342be78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 456)               228456    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 412)               188284    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 367)               151571    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 323)               118864    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 278)               90072     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 234)               65286     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 189)               44415     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 145)               27550     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1460      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,308,458\n",
            "Trainable params: 1,308,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# run model.summary() and make sure that you understand the model architecture that you just built \n",
        "# Notice in the model summary how the number of nodes have been linearly incremented in decreasing values. \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUc0jfnRm-uh"
      },
      "source": [
        "### Build a model, setting `negative_node_incrementation = False` \n",
        "\n",
        "Use `create_model` to build a model. \n",
        "\n",
        "- Set `n_layers = 10` \n",
        "- Set `first_layer_nodes = 100`\n",
        "- Set `last_layer_nodes = 500`\n",
        "- Set `act_funct = \"relu\"`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "3_-kqHQtm-ui",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5dcf5c585f07629a03086cf57ba53615",
          "grade": false,
          "grade_id": "cell-86d63e89a21223de",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# use create_model to create a model \n",
        "\n",
        "# YOUR CODE HERE\n",
        "model = create_model(n_layers=10, first_layer_nodes=100, last_layer_nodes=500, negative_node_incrementation=False,act_funct='relu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piboKWsNm-uj",
        "outputId": "c10f8443-4b59-4981-dc9d-8a9494583a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 145)               14645     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 189)               27594     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 234)               44460     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 278)               65330     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 323)               90117     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 367)               118908    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 412)               151616    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 456)               188328    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                4570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 784,068\n",
            "Trainable params: 784,068\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# run model.summary() and make sure that you understand the model architecture that you just built \n",
        "# Notice in the model summary how the number of nodes have been linearly incremented in decreasing values. \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBH7AR9p0OXi"
      },
      "source": [
        "## 1.2 Create a grid search using `sklearn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veloj7Nnlttf"
      },
      "source": [
        "### Hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e2lhZqP7mNn"
      },
      "outputs": [],
      "source": [
        "# define the grid search parameters\n",
        "param_grid = {'n_layers': [2, 3],\n",
        "              'epochs': [3], \n",
        "              \"first_layer_nodes\": [500, 300],\n",
        "              \"last_layer_nodes\": [100, 50]\n",
        "             }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ks_MLPB7mNn",
        "outputId": "293e3eae-c973-4532-86fb-79dcbe99f0b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Logan\\AppData\\Local\\Temp/ipykernel_17212/1702691071.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(create_model)\n"
          ]
        }
      ],
      "source": [
        "model = KerasClassifier(create_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8GKbLJ_7mNn",
        "outputId": "cf7d9084-4042-4518-a0ac-cdbd1edf1c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Epoch 1/3\n",
            "2344/2344 [==============================] - 4s 1ms/step - loss: 0.5911 - accuracy: 0.8191\n",
            "Epoch 2/3\n",
            "2344/2344 [==============================] - 3s 1ms/step - loss: 0.4081 - accuracy: 0.8777\n",
            "Epoch 3/3\n",
            "2344/2344 [==============================] - 3s 1ms/step - loss: 0.3310 - accuracy: 0.8984\n",
            "Best: 0.8668266534805298 using {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n",
            "Means: 0.8655733267466227, Stdev: 0.0052954828884920315 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 2}\n",
            "Means: 0.8584133187929789, Stdev: 0.007578531041235033 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 3}\n",
            "Means: 0.8643066684405009, Stdev: 0.004690446355012178 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 2}\n",
            "Means: 0.8668266534805298, Stdev: 0.0009843139780545513 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n",
            "Means: 0.8631333311398824, Stdev: 0.005745186310378684 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 2}\n",
            "Means: 0.8617866635322571, Stdev: 0.005131477284757555 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n",
            "Means: 0.8609066804250082, Stdev: 0.0050254055530916395 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
            "Means: 0.8587999939918518, Stdev: 0.0031081879584946687 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
            "CPU times: total: 1min\n",
            "Wall time: 1min 49s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=param_grid, \n",
        "                    n_jobs=-2, \n",
        "                    verbose=1, \n",
        "                    cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfH6okqe7mNo"
      },
      "outputs": [],
      "source": [
        "best_model = grid_result.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Inlda_0w7mNo",
        "outputId": "9c2fb2a3-eba3-420c-91a7-0163665488c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'epochs': 3,\n",
              " 'first_layer_nodes': 500,\n",
              " 'last_layer_nodes': 50,\n",
              " 'n_layers': 3,\n",
              " 'build_fn': <function __main__.create_model(n_layers, first_layer_nodes, last_layer_nodes, act_funct='relu', negative_node_incrementation=True)>}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrs3Yib17mNl"
      },
      "source": [
        "Ok, now that we've played around a bit with  `create_model`, let's build a  simpler model that we'll use to run gridsearches. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvegpS1-5yYX"
      },
      "source": [
        "### Build model\n",
        "\n",
        "Use `create_model` to build a model. \n",
        "\n",
        "- Set `n_layers = 2` \n",
        "- Set `first_layer_nodes = 500`\n",
        "- Set `last_layer_nodes = 100`\n",
        "- Set `act_funct = \"relu\"`\n",
        "- Make sure that `negative_node_incrementation = True`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-NcKYRr5yYX",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4ca6c5e51302fd10",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# use create_model to create a model \n",
        "\n",
        "###BEGIN SOLUTION\n",
        "# use create_model to create a model \n",
        "model  = create_model(n_layers=2, first_layer_nodes=500, last_layer_nodes=100, negative_node_incrementation=True,act_funct='relu')\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICLd6cYN5yYY",
        "outputId": "0e08e125-2923-4755-a562-df429d0fcab6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_23 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 10)                5010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 397,510\n",
            "Trainable params: 397,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# run model.summary() and make sure that you understand the model architecture that you just built \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwY6GFo85yYY"
      },
      "outputs": [],
      "source": [
        "# define the grid search parameters\n",
        "param_grid = {'n_layers': [2, 3],\n",
        "              'epochs': [3], \n",
        "              \"first_layer_nodes\": [500, 300],\n",
        "              \"last_layer_nodes\": [100, 50]\n",
        "             }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a0iHBqJ5yYY",
        "outputId": "b4d008d9-9d40-4706-9649-ded3adf11c6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Logan\\AppData\\Local\\Temp/ipykernel_17212/1702691071.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(create_model)\n"
          ]
        }
      ],
      "source": [
        "model = KerasClassifier(create_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxpuM3g15yYZ",
        "outputId": "2ad0da1d-39be-4980-9b6c-02254002afa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Epoch 1/3\n",
            "2344/2344 [==============================] - 4s 2ms/step - loss: 0.5921 - accuracy: 0.8198\n",
            "Epoch 2/3\n",
            "2344/2344 [==============================] - 4s 2ms/step - loss: 0.4105 - accuracy: 0.8758\n",
            "Epoch 3/3\n",
            "2344/2344 [==============================] - 4s 2ms/step - loss: 0.3330 - accuracy: 0.8976\n",
            "Best: 0.8664266665776571 using {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 3}\n",
            "Means: 0.8633333444595337, Stdev: 0.002630944716802637 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 2}\n",
            "Means: 0.8664266665776571, Stdev: 0.0038891560636718767 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 3}\n",
            "Means: 0.8598933418591818, Stdev: 0.006730312574769512 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 2}\n",
            "Means: 0.8635866840680441, Stdev: 0.005371555366817074 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n",
            "Means: 0.8613066673278809, Stdev: 0.0011053029656578586 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 2}\n",
            "Means: 0.8604666590690613, Stdev: 0.004690336630937439 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n",
            "Means: 0.8607066671053568, Stdev: 0.004460966877803956 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
            "Means: 0.8638933300971985, Stdev: 0.0024155688290898804 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
            "CPU times: total: 1min 1s\n",
            "Wall time: 1min 47s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=param_grid, \n",
        "                    n_jobs=-2, \n",
        "                    verbose=1, \n",
        "                    cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIlpwjag5yYZ"
      },
      "outputs": [],
      "source": [
        "best_model = grid_result.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFvMxmr85yYZ",
        "outputId": "a4320b01-498e-41af-834d-4caeb8acf28a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'epochs': 3,\n",
              " 'first_layer_nodes': 500,\n",
              " 'last_layer_nodes': 100,\n",
              " 'n_layers': 3,\n",
              " 'build_fn': <function __main__.create_model(n_layers, first_layer_nodes, last_layer_nodes, act_funct='relu', negative_node_incrementation=True)>}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6azV65Nb7mNo"
      },
      "source": [
        "-----\n",
        "\n",
        "# Experiment 2: Run the Gridsearch Algorithms \n",
        "\n",
        "In this section, we are going to use the same model and dataset in order to benchmark 3 different gridsearch approaches: \n",
        "\n",
        "- Gridsearch\n",
        "- Random Search\n",
        "- Bayesian Optimization. \n",
        "\n",
        "\n",
        "Our goal in this experiment is two-fold. We want to see which appraoch \n",
        "\n",
        "- Scores the highest accuracy\n",
        "- Has the shortest run time \n",
        "\n",
        "We want to see how these 3 gridsearch approaches handle these trade-offs and to give you a sense of those trades offs.\n",
        "\n",
        "### Trade-offs\n",
        "\n",
        "`Gridsearch` will train a model on every single unique hyperparameter combination, this guarantees that you'll get the highest possible accuracy from your parameter set but your gridsearch might have a very long run-time. \n",
        "\n",
        "`Random Search` will randomly sample from your parameter set which, depending on how many samples, the run-time might be significantly cut down but you might or might not sample the parameters that correspond to the heightest possible accuracies. \n",
        "\n",
        "`Bayesian Optimization` has a bit of intelligence built into it's search algorithm but you do need to manually select some parameters which may greatly influence the model learning outcomes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X41u_hls7mNp"
      },
      "source": [
        "-------\n",
        "### Build our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ_uyKlj7mNp"
      },
      "outputs": [],
      "source": [
        "# because gridsearching can take a lot of time and we are bench marking 3 different approaches\n",
        "# let's build a simple model to minimize run time \n",
        "\n",
        "def build_model(hp):\n",
        "    \n",
        "    \"\"\"\n",
        "    Returns a complied keras model ready for keras-tuner gridsearch algorithms \n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units=hp.get('units'),activation=hp.get(\"activation\")))\n",
        "    \n",
        "    # output layer\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(hp.get('learning_rate')),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PYE7rTku7mNp",
        "outputId": "10c8a8f5-fd6d-46fb-e09e-032b0f13ef3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'relu'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# build out our hyperparameter dictionary \n",
        "hp = HyperParameters()\n",
        "hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3])\n",
        "hp.Choice('activation',values=[\"relu\", \"sigmoid\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqjp2kHD7mNu"
      },
      "source": [
        "---------\n",
        "## 2.1 Gridsearch Optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsNW4rJp7mNu"
      },
      "source": [
        "### Populate a `sklearn` compatible parameter dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJQFKoyL7mNu"
      },
      "outputs": [],
      "source": [
        "# build out our hyperparameter dictionary \n",
        "hyper_parameters = {\n",
        "    # BUG Fix: cast array as list otherwise GridSearchCV will throw error\n",
        "    \"units\": np.arange(32, 512, 32).tolist(),\n",
        "    \"learning_rate\": [1e-1, 1e-2, 1e-3],\n",
        "    \"activation\":[\"relu\", \"sigmoid\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcxV58iC7mNu",
        "outputId": "8190fdad-4ac4-4caf-b257-579ad93e2ec3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'units': [32,\n",
              "  64,\n",
              "  96,\n",
              "  128,\n",
              "  160,\n",
              "  192,\n",
              "  224,\n",
              "  256,\n",
              "  288,\n",
              "  320,\n",
              "  352,\n",
              "  384,\n",
              "  416,\n",
              "  448,\n",
              "  480],\n",
              " 'learning_rate': [0.1, 0.01, 0.001],\n",
              " 'activation': ['relu', 'sigmoid']}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hyper_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOoMg9Ao7mNv"
      },
      "source": [
        "### Build a `sklearn` compatible model function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZFVl-I-7mNv"
      },
      "outputs": [],
      "source": [
        "def build_model(units=25, learning_rate=hp.get(\"learning_rate\"), activation=hp.get(\"activation\")):\n",
        "    \n",
        "    \"\"\"\n",
        "    Returns a complie keras model ready for keras-tuner gridsearch algorithms \n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units=hp.Int('units',\n",
        "                                        min_value=32,\n",
        "                                        max_value=512,\n",
        "                                        step=32), activation=activation))\n",
        "    \n",
        "    # output layer\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqYmn3QFsqZ_"
      },
      "source": [
        "### Apply the \"wrapper\" to make the model compatible with `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABSzrTrH7mNw",
        "outputId": "4509c819-6c87-4de4-c8ee-88238ac2c243"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Logan\\AppData\\Local\\Temp/ipykernel_17212/3788592660.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn = build_model)\n"
          ]
        }
      ],
      "source": [
        "model = KerasClassifier(build_fn = build_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTawllrN7mNw",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "5ba12346-8969-4ae1-fa9c-866cb1a80354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 90 candidates, totalling 270 fits\n",
            "2344/2344 [==============================] - 2s 729us/step - loss: 0.8108 - accuracy: 0.7625\n",
            "Best: 0.7967066566149393 using {'activation': 'relu', 'learning_rate': 0.001, 'units': 448}\n",
            "Means: 0.26471999784310657, Stdev: 0.04601944562942597 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 32}\n",
            "Means: 0.2621333251396815, Stdev: 0.048670266021052254 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 64}\n",
            "Means: 0.26099999745686847, Stdev: 0.0471642652859652 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 96}\n",
            "Means: 0.23372000455856323, Stdev: 0.02297855727647006 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 128}\n",
            "Means: 0.22401333848635355, Stdev: 0.04642937918649174 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 160}\n",
            "Means: 0.21305333077907562, Stdev: 0.03142062690021512 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 192}\n",
            "Means: 0.26663999756177265, Stdev: 0.038373779810284996 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 224}\n",
            "Means: 0.23765332996845245, Stdev: 0.06428406687439302 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 256}\n",
            "Means: 0.25350667039553326, Stdev: 0.014972770099288988 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 288}\n",
            "Means: 0.20865333080291748, Stdev: 0.048026007633165536 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 320}\n",
            "Means: 0.2195600022872289, Stdev: 0.06756198227797872 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 352}\n",
            "Means: 0.2466666599114736, Stdev: 0.047462369422431205 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 384}\n",
            "Means: 0.22127999862035116, Stdev: 0.059911482114780486 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 416}\n",
            "Means: 0.2634933392206828, Stdev: 0.08617918145883406 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 448}\n",
            "Means: 0.22413333505392075, Stdev: 0.10785707125451689 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 480}\n",
            "Means: 0.7846133311589559, Stdev: 0.006202976529132664 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 32}\n",
            "Means: 0.7840266625086466, Stdev: 0.0052679117389672105 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 64}\n",
            "Means: 0.7879199981689453, Stdev: 0.0015304998242811935 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 96}\n",
            "Means: 0.7876399954160055, Stdev: 0.006958847358058715 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 128}\n",
            "Means: 0.7897999882698059, Stdev: 0.0016486003224652542 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 160}\n",
            "Means: 0.7844266692797343, Stdev: 0.006534632113966718 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 192}\n",
            "Means: 0.7894933223724365, Stdev: 0.0037429805557361133 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 224}\n",
            "Means: 0.7886799971262614, Stdev: 0.009123322036920045 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 256}\n",
            "Means: 0.7771066625912985, Stdev: 0.0035406078790445415 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 288}\n",
            "Means: 0.7794533371925354, Stdev: 0.005481646101051634 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 320}\n",
            "Means: 0.7873866558074951, Stdev: 0.002427475770032499 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 352}\n",
            "Means: 0.790880004564921, Stdev: 0.015086570842906363 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 384}\n",
            "Means: 0.7836400071779887, Stdev: 0.005875895614652131 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 416}\n",
            "Means: 0.7852266629536947, Stdev: 0.0033519510234380698 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 448}\n",
            "Means: 0.7843866546948751, Stdev: 0.0018957658171814583 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 480}\n",
            "Means: 0.7887200117111206, Stdev: 0.0068816472661156255 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 32}\n",
            "Means: 0.7904133200645447, Stdev: 0.00971159178948214 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 64}\n",
            "Means: 0.7906133532524109, Stdev: 0.003025276714908609 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 96}\n",
            "Means: 0.7885199785232544, Stdev: 0.0031669939737197874 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 128}\n",
            "Means: 0.7872133255004883, Stdev: 0.005816884175752904 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 160}\n",
            "Means: 0.7934399843215942, Stdev: 0.005797193824461234 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 192}\n",
            "Means: 0.7886000076929728, Stdev: 0.009788864860593702 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 224}\n",
            "Means: 0.7880933086077372, Stdev: 0.009608347258991077 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 256}\n",
            "Means: 0.7867333292961121, Stdev: 0.005958642337952707 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 288}\n",
            "Means: 0.7827066580454508, Stdev: 0.00590234555266058 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 320}\n",
            "Means: 0.7873466610908508, Stdev: 0.008529290751345177 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 352}\n",
            "Means: 0.7890533208847046, Stdev: 0.005958910778519964 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 384}\n",
            "Means: 0.781386653582255, Stdev: 0.006282775612500347 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 416}\n",
            "Means: 0.7967066566149393, Stdev: 0.0036493312876900125 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 448}\n",
            "Means: 0.788320004940033, Stdev: 0.0051679975287335905 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 480}\n",
            "Means: 0.6533199946085612, Stdev: 0.022836431385766864 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 32}\n",
            "Means: 0.6545466581980387, Stdev: 0.017917617512009047 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 64}\n",
            "Means: 0.6783999999364217, Stdev: 0.012209161130984202 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 96}\n",
            "Means: 0.6462000211079916, Stdev: 0.004308621954359319 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 128}\n",
            "Means: 0.6697466572125753, Stdev: 0.012998666696036143 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 160}\n",
            "Means: 0.6554666757583618, Stdev: 0.01489718914593732 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 192}\n",
            "Means: 0.6533066630363464, Stdev: 0.01009578263116974 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 224}\n",
            "Means: 0.6492800116539001, Stdev: 0.013182909424203755 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 256}\n",
            "Means: 0.6424799958864847, Stdev: 0.010111069596722958 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 288}\n",
            "Means: 0.6741066773732504, Stdev: 0.007156713968788073 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 320}\n",
            "Means: 0.6586533387502035, Stdev: 0.01399506036115625 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 352}\n",
            "Means: 0.6776666641235352, Stdev: 0.017795900433178437 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 384}\n",
            "Means: 0.6677066485087076, Stdev: 0.01876974742696956 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 416}\n",
            "Means: 0.6367066701253256, Stdev: 0.005283646974671279 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 448}\n",
            "Means: 0.6731200019518534, Stdev: 0.004650428465147602 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 480}\n",
            "Means: 0.7868000070254008, Stdev: 0.011090463775401696 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 32}\n",
            "Means: 0.7879066864649454, Stdev: 0.009133109397398299 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 64}\n",
            "Means: 0.7888000011444092, Stdev: 0.0069586285700238455 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 96}\n",
            "Means: 0.7842400074005127, Stdev: 0.0028040068597300497 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 128}\n",
            "Means: 0.7869866689046224, Stdev: 0.004213160747874691 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 160}\n",
            "Means: 0.7892666657765707, Stdev: 0.004451977608520483 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 192}\n",
            "Means: 0.7893733382225037, Stdev: 0.006264413773748975 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 224}\n",
            "Means: 0.7885599931081136, Stdev: 0.0013975212747938846 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 256}\n",
            "Means: 0.7904933492342631, Stdev: 0.003130304384404735 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 288}\n",
            "Means: 0.7835599978764852, Stdev: 0.0019244296009633959 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 320}\n",
            "Means: 0.7841866612434387, Stdev: 0.0024510743087867663 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 352}\n",
            "Means: 0.7813733418782552, Stdev: 0.005734220075312983 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 384}\n",
            "Means: 0.7827733357747396, Stdev: 0.0036786003441801425 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 416}\n",
            "Means: 0.7819466590881348, Stdev: 0.008938612979752646 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 448}\n",
            "Means: 0.7869866689046224, Stdev: 0.006503927443122615 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 480}\n",
            "Means: 0.7624133427937826, Stdev: 0.0044427356146962685 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 32}\n",
            "Means: 0.7619200150171915, Stdev: 0.005329565516185168 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 64}\n",
            "Means: 0.7601733207702637, Stdev: 0.005921660507797513 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 96}\n",
            "Means: 0.7605066696802775, Stdev: 0.0061190052837087495 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 128}\n",
            "Means: 0.7602933247884115, Stdev: 0.001996623655446658 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 160}\n",
            "Means: 0.7596266667048136, Stdev: 0.002875976191155084 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 192}\n",
            "Means: 0.7607733408610026, Stdev: 0.005444737518217977 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 224}\n",
            "Means: 0.7606799999872843, Stdev: 0.004216651010044625 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 256}\n",
            "Means: 0.7648533384005228, Stdev: 0.006537371550055199 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 288}\n",
            "Means: 0.7602666616439819, Stdev: 0.00535674646266174 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 320}\n",
            "Means: 0.7598666747411092, Stdev: 0.005990256555892743 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 352}\n",
            "Means: 0.7615599830945333, Stdev: 0.005962106155639006 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 384}\n",
            "Means: 0.7621866464614868, Stdev: 0.005598511628928157 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 416}\n",
            "Means: 0.7615866661071777, Stdev: 0.004900540192183875 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 448}\n",
            "Means: 0.759880006313324, Stdev: 0.0034973352745562183 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 480}\n"
          ]
        }
      ],
      "source": [
        "# save start time \n",
        "start = time()\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=hyper_parameters, \n",
        "                    n_jobs=-2, \n",
        "                    verbose=1, \n",
        "                    cv=3)\n",
        "\n",
        "#grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# save end time \n",
        "end = time()\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THKMZLNv7mNw",
        "outputId": "cd3805e3-dd6e-4f41-935a-60a34c43e31c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.6901416182518005"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# total run time \n",
        "total_run_time_in_miniutes = (end - start)/60\n",
        "total_run_time_in_miniutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XgJsrZb7mNx",
        "outputId": "e2bf0626-41e4-4c0f-cf51-48d71f9ab200"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'relu', 'learning_rate': 0.001, 'units': 448}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_result.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYufbSI87mNx",
        "outputId": "ad8996a6-254e-4f8a-fae8-e69d5ebdd769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 571us/step - loss: 0.6823 - accuracy: 0.7967\n"
          ]
        }
      ],
      "source": [
        "# because all other optimization approaches are reporting test set score\n",
        "# let's calculate the test set score in this case \n",
        "best_model = grid_result.best_estimator_\n",
        "test_acc = best_model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlR-pVwP7mNx",
        "outputId": "ce384780-2072-4454-ff53-d1713744af44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7966799736022949"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj4jJ0Qm7mNx"
      },
      "source": [
        " ### Results\n",
        " \n",
        "Identify and write the the best performing hyperparameter combination and model score. \n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "10px3N2q7mNx",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9577db883482c6cded3836e5cfbf5a74",
          "grade": true,
          "grade_id": "cell-eb06d682d2790f6e",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "The best performing hyperparamaters were a relu for activation, 0.001 for learning,\n",
        "and 416 for units"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu-lBWph7mNq"
      },
      "source": [
        "------\n",
        "## 2.2 Random Search with `keras-tuner`\n",
        "\n",
        "Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `RandomSearch` tuner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "8DApqLli7mNq",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "aaff9aae33845f374e15f2381719d83a",
          "grade": false,
          "grade_id": "cell-8c1dfb9b6d12bea2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# how many unique hyperparameter combinations do we have? \n",
        "# HINT: take the product of the number of possible values for each hyperparameter \n",
        "# save your answer to n_unique_hparam_combos\n",
        "\n",
        "# YOUR CODE HERE\n",
        "n_unique_hparam_combos = 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "m1UKRA597mNq",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a9d628451e83431e1b52da10eccf2c00",
          "grade": false,
          "grade_id": "cell-1fa83950bb2d5f92",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# how many of these do we want to randomly sample?\n",
        "# let's pick 25% of n_unique_hparam_combos param combos to sample\n",
        "# save this number to n_param_combos_to_sample\n",
        "\n",
        "# YOUR CODE HERE\n",
        "fraction_to_sample = 0.25\n",
        "n_param_combos_to_sample = 5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TzaNnzoQU4U"
      },
      "source": [
        "### Instantiate a `RandomSearch()` object for your grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9PCHLBWQPcb",
        "outputId": "8880fcbc-fbb2-44a6-a230-1a125bd8631c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./keras-tuner-trial\\random_search\\oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from ./keras-tuner-trial\\random_search\\tuner0.json\n"
          ]
        }
      ],
      "source": [
        "random_tuner = RandomSearch(\n",
        "            build_model,\n",
        "            objective='val_accuracy',\n",
        "            max_trials=n_param_combos_to_sample, # number of times to sample the parameter set and build a model \n",
        "            seed=1234,\n",
        "            hyperparameters=hp, # pass in our hyperparameter dictionary\n",
        "            directory='./keras-tuner-trial',\n",
        "            project_name='random_search')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGFdv1qE7mNr",
        "outputId": "f4fb1482-c4bc-40cd-c426-d8248e67341f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        " # take note of Total elapsed time in print out -- took ~10 minutes without GPU\n",
        "random_tuner.search(X_train, y_train,\n",
        "                    epochs=3,\n",
        "                    validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E60FH0e6furt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNBUhIe97mNr",
        "outputId": "a12fb52d-eec7-4b72-a2d0-cfb8482ade48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./keras-tuner-trial\\random_search\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x000001FDACF72D00>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 352\n",
            "learning_rate: 0.001\n",
            "activation: relu\n",
            "Score: 0.2449599951505661\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 384\n",
            "learning_rate: 0.01\n",
            "activation: relu\n",
            "Score: 0.24063999950885773\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 480\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.17936000227928162\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 288\n",
            "learning_rate: 0.1\n",
            "activation: relu\n",
            "Score: 0.1701200008392334\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 96\n",
            "learning_rate: 0.1\n",
            "activation: relu\n",
            "Score: 0.1629599928855896\n"
          ]
        }
      ],
      "source": [
        "# identify the best score and hyperparamter (should be at the top since scores are ranked)\n",
        "random_tuner.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRpQVXBE7mNr",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        " ### Results\n",
        " \n",
        "Identify and write the the best performing hyperparameter combination and model score. \n",
        "Note that because this is Random Search, multiple runs might have slighly different outcomes. \n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "aQjMc84c7mNs",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f084b5d373f8589a1de8d6d4473b974a",
          "grade": true,
          "grade_id": "cell-5527738b6382c164",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXjW7eYA7mNs"
      },
      "source": [
        "------\n",
        "## 2.3 Bayesian Optimization with `keras-tuner`\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/0/02/GpParBayesAnimationSmall.gif)\n",
        "\n",
        "Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `BayesianOptimization` tuner.\n",
        "\n",
        "Pay special attention to these `BayesianOptimization` parameters: `num_initial_points` and `beta`. \n",
        "\n",
        "`num_initial_points`: \n",
        "\n",
        "Number of randomly selected hyperparameter combinations to try before applying bayesian probability to determine liklihood of which param combo to try next based on expected improvement\n",
        "\n",
        "\n",
        "`beta`: \n",
        "\n",
        "Larger values means more willing to explore new hyperparameter combinations (analogous to searching for the global minimum in Gradient Descent), smaller values means that it is less willing to try new hyperparameter combinations (analogous to getting stuck in a local minimum in Gradient Descent). \n",
        "\n",
        "As a start, error on the side of larger values. What defines a small or large value you ask? That question would pull us into the mathematical intricacies of Bayesian Optimization and Gaussian Processes. For simplicity, notice that the default value is 2.6 and work from there. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NXjQBn47mNs"
      },
      "outputs": [],
      "source": [
        "# we know that 24 samples is about 25% of 96 possible hyper-parameter combos\n",
        "# let's set up a run with the same parameters we used for RandomSearch() so the comparison will be aplles-to-apples\n",
        "# feel free to play with any of these numbers later\n",
        "max_trials=24\n",
        "num_initial_points=5\n",
        "beta=5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhZNIJZ4RS5Y"
      },
      "source": [
        "#### Instantiate a `BayesianOptimization()` object for your grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33joO_J97mNs"
      },
      "outputs": [],
      "source": [
        "bayesian_tuner = BayesianOptimization(\n",
        "                    build_model,\n",
        "                    objective='val_accuracy',\n",
        "                    max_trials=max_trials,\n",
        "                    hyperparameters=hp, # pass in our hyperparameter dictionary\n",
        "                    num_initial_points=num_initial_points, \n",
        "                    beta=beta, \n",
        "                    seed=1234,\n",
        "                    directory='./keras-tuner-trial',\n",
        "                    project_name='bayesian_optimization_4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9AM5Pdj7mNt",
        "outputId": "6ca1e102-3836-4d46-c535-572f8a7f085c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 24 Complete [00h 00m 07s]\n",
            "val_accuracy: 0.1428000032901764\n",
            "\n",
            "Best val_accuracy So Far: 0.3166399896144867\n",
            "Total elapsed time: 00h 03m 12s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "bayesian_tuner.search(X_train, y_train,\n",
        "               epochs=3,\n",
        "               validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJcHC8d87mNt",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "a610cf67-6251-4976-9409-30a57ed02be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./keras-tuner-trial\\bayesian_optimization_4\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x000001FDAC897970>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 512\n",
            "learning_rate: 0.1\n",
            "activation: relu\n",
            "Score: 0.3166399896144867\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 352\n",
            "learning_rate: 0.001\n",
            "activation: relu\n",
            "Score: 0.31439998745918274\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 512\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.30243998765945435\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 512\n",
            "learning_rate: 0.1\n",
            "activation: relu\n",
            "Score: 0.30188000202178955\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 352\n",
            "learning_rate: 0.001\n",
            "activation: relu\n",
            "Score: 0.30055999755859375\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 352\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.2932800054550171\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 320\n",
            "learning_rate: 0.001\n",
            "activation: relu\n",
            "Score: 0.2844800055027008\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 256\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.2585200071334839\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 192\n",
            "learning_rate: 0.001\n",
            "activation: relu\n",
            "Score: 0.25764000415802\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 352\n",
            "learning_rate: 0.001\n",
            "activation: relu\n",
            "Score: 0.2561199963092804\n"
          ]
        }
      ],
      "source": [
        "bayesian_tuner.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woo9D9AU7mNu"
      },
      "source": [
        " ### Results\n",
        " \n",
        "Identify and write the the best performing hyperparameter combination and model score. \n",
        "Note that because this is  Bayesian Optimization, multiple runs might have slighly different outcomes. \n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "1EXa47mH7mNu",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1badcdca408cdd49bc2e409dca3bac5a",
          "grade": true,
          "grade_id": "cell-ff95600bf745f40f",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "The best hyper parameters were \n",
        "units: 512\n",
        "learning_rate: 0.1\n",
        "activation: relu\n",
        "Score: 0.3166399896144867"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOZ5-tJDraFE"
      },
      "source": [
        "We should point out that Gridsearch split the training set internally and created a test set whereas keras-tuner allows us to pass in a test set. This means that the keras-tuner algorithms were using one test set and our skearn GridSearchCV was using a different test set - so this isn't a perfectly exact 1-to-1 comparision but it'll have to do. In order to compensate for this, we did score the best model on the same test set that keras-tuner used. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPYChhrC7mNx"
      },
      "source": [
        "_______\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "The spirit of this experiment is to expose you to the idea of benchmarking and comparing the trade-offs of various gridsearch approaches. \n",
        "\n",
        "Even if we did find a way to pass in the original test set into GridSearchCV, we can see that both Random Search and Bayesian Optimization are arguably better alternatives to a brute force grid search when we consider the trade-offs of run time and locating the best performing model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sth1AfwX7mNy"
      },
      "source": [
        "----\n",
        "\n",
        "# Stretch Goals\n",
        "\n",
        "- Feel free to run whatever gridsearch experiments on whatever models you like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2APQG9H7mNy"
      },
      "outputs": [],
      "source": [
        "# this is your open playground - be free to explore as you wish "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DS_423_Tune_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "nteract": {
      "version": "0.22.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}