{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b29cb9a438a53a188052be3a3371c6f7",
          "grade": false,
          "grade_id": "cell-e98be1092b48b377",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "e-HImofQvaQ4"
      },
      "source": [
        "# Sprint Challenge\n",
        "## *Data Science Unit 4 Sprint 1*\n",
        "\n",
        "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
        "\n",
        "The real dataset is massive (almost 8 gigs uncompressed). The data is sampled for you to something more manageable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, add comments and conclusions about your findings and describe anything you want to analyze in the future.\n",
        "\n",
        "## Challenge Objectives\n",
        "Successfully complete all these objectives to earn full credit. \n",
        "\n",
        "**Successful completion is defined as passing all the unit tests in each objective.**  \n",
        "\n",
        "Each unit test that you pass is 1 point. \n",
        "\n",
        "There are 5 total possible points in this sprint challenge. \n",
        "\n",
        "\n",
        "There are more details on each objective further down in the notebook.*\n",
        "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
        "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
        "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on Yelp rating\n",
        "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "3) **Comment out the cell that generates a pyLDAvis visual in objective 4 (see instructions in that section).** \n",
        "____"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyLDAvis==3.3.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wziUTYnj3Xov",
        "outputId": "4b130742-11e2-4bc2-b0f7-2b8b2707891c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis==3.3.1 in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (1.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (2.11.3)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (1.17)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (0.16.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (3.6.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (1.1.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (0.0)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==3.3.1) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis==3.3.1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis==3.3.1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis==3.3.1) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis==3.3.1) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis==3.3.1) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis==3.3.1) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis==3.3.1) (3.0.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis==3.3.1) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkkYoHnA3Xww",
        "outputId": "9ff4a3b7-6149-41e1-9db6-106679ebc8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 43.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a0fb09b9e122fc2f2a2baae91a22a818",
          "grade": false,
          "grade_id": "cell-e6c3d2173420a581",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "COmYwlDEvaQ6"
      },
      "source": [
        "### Part 0: Import Necessary Packages\n",
        "For this section, you will need to import:\n",
        "- `spacy` \n",
        "- `Pandas`\n",
        "- `Seaborn`\n",
        "- `Matplotlib`\n",
        "- `NearestNeighbors`\n",
        "- `Pipeline` \n",
        "- `TfidfVectorizer`\n",
        "- `KneighborsClassifier`\n",
        "- `GridSearchCV`\n",
        "- `corpora`\n",
        "- `LdaModel`\n",
        "- `gensim`\n",
        "- `re`\n",
        "\n",
        "> **Note: This assignment is optimized to work with these specific packages. You can use import different packages, but note that this may affect how CodeGrade works, and may cause CodeGrade to fail.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8d3d0719eecd5609256125d84cc4218a",
          "grade": false,
          "grade_id": "cell-b29df5c5bfb8c0d8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx8pcGvxvaQ7",
        "outputId": "c7d6d7b1-ff28-4d23-b291-531e49ee9157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.7/dist-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Mapping\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
            "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
            "  _deprecated()\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio5.py:98: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from .mio5_utils import VarReader5\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import spacy\n",
        "spacy.util.fix_random_seed(0)\n",
        "\n",
        "# import pyLDAvis\n",
        "# import pyLDAvis.gensim_models \n",
        "\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6b8ad4a1ac317df7b82aced26eee406f",
          "grade": true,
          "grade_id": "cell-be1ef923d085ceb5",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "au4cBc7OvaQ8"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert pd.__package__ == 'pandas'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "11b700564f5d76c1ec246d8fece821c1",
          "grade": false,
          "grade_id": "cell-c94bee05bece8c59",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8mighFukvaQ8"
      },
      "source": [
        "\n",
        "\n",
        "### Part 0: Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "150e28699f961709cb59be5e0f8ddbe0",
          "grade": false,
          "grade_id": "cell-395851cd95d17235",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "UP6p0ET9vaQ8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Load reviews from URL\n",
        "data_url = 'https://raw.githubusercontent.com/bloominstituteoftechnology/data-science-practice-datasets/main/unit_4/unit1_nlp/review_sample.json'\n",
        "\n",
        "# Import data into a DataFrame named df\n",
        "df = pd.read_json(data_url, lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "356579363f311da83f4ef7abaf3c9212",
          "grade": true,
          "grade_id": "cell-cb5006475e42b8f9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "e69tnB7vvaQ9"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert isinstance(df, pd.DataFrame), 'df is not a DataFrame. Did you import the data into df?'\n",
        "assert df.shape[0] == 10000, 'DataFrame df has the wrong number of rows.'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r--T_WIn62Yd",
        "outputId": "f9ed14ee-a969-43c5-bf9a-6d2792f794b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              business_id  cool                date  funny  \\\n",
              "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
              "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
              "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
              "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
              "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
              "\n",
              "                review_id  stars  \\\n",
              "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
              "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
              "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
              "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
              "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
              "\n",
              "                                                text  useful  \\\n",
              "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
              "1  Came here for lunch Togo. Service was quick. S...       0   \n",
              "2  I've been to Vegas dozens of times and had nev...       2   \n",
              "3  We went here on a night where they closed off ...       5   \n",
              "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
              "\n",
              "                  user_id  \n",
              "0  n1LM36qNg4rqGXIcvVXv8w  \n",
              "1  5CgjjDAic2-FAvCtiHpytA  \n",
              "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
              "3  cZZnBqh4gAEy4CdNvJailQ  \n",
              "4  n9QO4ClYAS7h9fpQwa5bhA  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-377800bc-2a6b-4a85-b1eb-38f7d81d9879\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-03-31 16:50:30</td>\n",
              "      <td>0</td>\n",
              "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
              "      <td>1</td>\n",
              "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
              "      <td>10</td>\n",
              "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-12-16 05:31:03</td>\n",
              "      <td>0</td>\n",
              "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
              "      <td>4</td>\n",
              "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
              "      <td>0</td>\n",
              "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-06-20 19:14:48</td>\n",
              "      <td>1</td>\n",
              "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
              "      <td>3</td>\n",
              "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
              "      <td>2</td>\n",
              "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
              "      <td>3</td>\n",
              "      <td>2010-07-13 00:33:45</td>\n",
              "      <td>4</td>\n",
              "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
              "      <td>1</td>\n",
              "      <td>We went here on a night where they closed off ...</td>\n",
              "      <td>5</td>\n",
              "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-06-30 02:30:01</td>\n",
              "      <td>0</td>\n",
              "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
              "      <td>4</td>\n",
              "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
              "      <td>5</td>\n",
              "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-377800bc-2a6b-4a85-b1eb-38f7d81d9879')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-377800bc-2a6b-4a85-b1eb-38f7d81d9879 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-377800bc-2a6b-4a85-b1eb-38f7d81d9879');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(text):\n",
        "    \"\"\"\n",
        "    Accepts a single text document and performs several regex substitutions in order to clean the document. \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    text: string or object \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    text: string or object\n",
        "    \"\"\"\n",
        "    \n",
        "    # order of operations - apply the expression from top to bottom\n",
        "    date_regex = r\"\\d+/\\d+/\\d+\"\n",
        "    punct_regex = r\"[^a-zA-Z\\s]\" # any non-alphanumeric chars\n",
        "    special_chars_regex = r\"[\\$\\%\\&\\@+]\" \n",
        "    numerical_regex =  r\"\\d+\"  # match one or more digits\n",
        "    \n",
        "    # Replace any strings matching the above regex patterns with blank strings\n",
        "    # (effectively removing them from the text)\n",
        "    text = re.sub(date_regex, \"\", text)\n",
        "    text = re.sub(punct_regex, \"\", text)\n",
        "    text = re.sub(special_chars_regex, \"\", text)\n",
        "    text = re.sub(numerical_regex, \"\", text)\n",
        "    return text.lower()"
      ],
      "metadata": {
        "id": "hfRW3_SeKHUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].astype(str)"
      ],
      "metadata": {
        "id": "u6S-Ol7jKvcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(clean_data)\n",
        "\n",
        "df['text'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ciZLZXi6KJFd",
        "outputId": "244b3a17-c4ba-4f89-f916-41ff990109f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'beware fake fake fakewe also own a small business in los alamitos ca and received what looked like a legitimate bill for  with an account number and all  i called the phone number listed    the wait time on hold said  minutes and to leave a message  i could not get a live person on the phone no matter what number i selected  i left a very firm message that i would be contacting the bbb and my attorney regarding their company trying to scam businesses this has to be illegal'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_hCIaRoKJK4",
        "outputId": "56e169b5-25a2-452c-e619-801c0a184c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "business_id            object\n",
              "cool                    int64\n",
              "date           datetime64[ns]\n",
              "funny                   int64\n",
              "review_id              object\n",
              "stars                   int64\n",
              "text                   object\n",
              "useful                  int64\n",
              "user_id                object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "aedd47e33e28a74846b51e236deef316",
          "grade": false,
          "grade_id": "cell-27dc6b438d2f2722",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JOxcaYSbvaQ9"
      },
      "source": [
        "## Part 1: Tokenize Function\n",
        "<a id=\"#p1\"></a>\n",
        "\n",
        "Complete the function `tokenize`. Your function should\n",
        "- Accept one document at a time\n",
        "- Return a list of tokens\n",
        "\n",
        "You are free to use any method you have learned this week."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JRr-ESkvaQ-"
      },
      "outputs": [],
      "source": [
        "# Optional: Consider using spaCy in your function. The spaCy library can be imported by running this cell.\n",
        "# A pre-trained model (en_core_web_sm) has been made available to you in the CodeGrade container.\n",
        "# If you DON'T need use the en_core_web_sm model, you can comment it out below.\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4837ed2a1cc13057ba40203859d46ff6",
          "grade": false,
          "grade_id": "cell-3d570d5a1cd6cb64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "0pb219WSvaQ_"
      },
      "outputs": [],
      "source": [
        "def tokenize(document):\n",
        "    \"\"\"\n",
        "    Takes a doc (text string) and returns a list of tokens in the form of lemmas.\n",
        "    Filters out Stop words, punctuation, and leading/trailing spaces. \n",
        "    \"\"\"\n",
        "    doc = nlp(document)\n",
        "    return [token.lemma_.lower().strip() for token in doc if (not token.is_punct) and (not token.is_stop) and (not token.is_space)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2181ca9d36070260b1f75dcfd9e58965",
          "grade": true,
          "grade_id": "cell-02da164f6fbe730a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "LOjRPGnAvaQ_"
      },
      "outputs": [],
      "source": [
        "'''Testing'''\n",
        "assert isinstance(tokenize(df.sample(n=1)[\"text\"].iloc[0]), list), \"Make sure your tokenizer function accepts a single document and returns a list of tokens!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d4137c3ea2fa84821d1dbf1b28dde6dd",
          "grade": false,
          "grade_id": "cell-ef13337bc7694c52",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WHpMhCv4vaQ_"
      },
      "source": [
        "## Part 2: Vector Representation\n",
        "<a id=\"#p2\"></a>\n",
        "1. Create a vector representation of the reviews (i.e. create a doc-term matrix).\n",
        "    * Name that doc-term matrix `dtm`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df[\"tokens\"] = df.text.apply(tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWkAxV5lnNXv",
        "outputId": "98a1427c-20d3-4aa8-df92-12a75e034078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 10s, sys: 2.45 s, total: 4min 13s\n",
            "Wall time: 4min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate vectorizer object\n",
        "tfidf_vect = TfidfVectorizer(max_features=100)\n",
        "\n",
        "# DOING THE FIT AND TRANSFORM SEPARATELY!!!\n",
        "# Create a vocabulary and get word counts per document\n",
        "vocab = tfidf_vect.fit(df.text)\n",
        "\n",
        "# Get the word tfidf scores \n",
        "dtm = tfidf_vect.transform(df.text)\n",
        "\n",
        "# View Feature Matrix as DataFrame\n",
        "dtm = pd.DataFrame(data=dtm.toarray(), columns=tfidf_vect.get_feature_names())"
      ],
      "metadata": {
        "id": "5lQl3OiCa5sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "86048b7ea6cb011227aefa5a8f7a9e65",
          "grade": false,
          "grade_id": "cell-33c058ea193687c3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7uAcOWXgvaRA"
      },
      "source": [
        "\n",
        "2. Write a fake review. Assign the text of the review to an object called `fake_review`. \n",
        "3. Query the fake review for the 10 most similar reviews, print the text of the reviews. \n",
        "    - Given the size of the dataset, use `NearestNeighbors` model for this. Name the model `nn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f6aa466983420c836879d744ffa6c9a8",
          "grade": false,
          "grade_id": "cell-3d5bc610a8ec6b24",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "UUtpA-n6vaRA"
      },
      "outputs": [],
      "source": [
        "# Create and fit a NearestNeighbors model named \"nn\"\n",
        "# YOUR CODE HERE\n",
        "fake_review = 'I hated it so much. Bahumbug. I hate it because I am an idiot.'\n",
        "fake_review_query = [fake_review]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # vectorize your ideal job description using your fitted tfidf vectorizer \n",
        "fake_review_vector = tfidf_vect.transform(fake_review_query).toarray()\n",
        "\n",
        "# fit NearestNeighbors model to the Indeed reviews document-term matrix that you created\n",
        "top_n_neigh = 10\n",
        "# instantiate a Nearest Neighbors model\n",
        "nn = NearestNeighbors(n_neighbors=top_n_neigh)\n",
        "# Fit the NN model on our DTM\n",
        "nn.fit(dtm)\n",
        "\n",
        "# get top_n_neigh distances and review indices for reviews that are closest to your ideal job\n",
        "n_dist, n_ind = nn.kneighbors(fake_review_vector)\n"
      ],
      "metadata": {
        "id": "ouClPOa1HMRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d270ed23df3c7d3c6cf08ab174ccaf9e",
          "grade": true,
          "grade_id": "cell-c43704dcff67e99b",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ss36S3wFvaRA"
      },
      "outputs": [],
      "source": [
        "'''Testing.'''\n",
        "assert nn.__module__ == 'sklearn.neighbors._unsupervised', ' nn is not a NearestNeighbors instance.'\n",
        "assert nn.n_neighbors == 10, 'nn has the wrong value for n_neighbors'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3da2ced9f187ed0aa1a890785e2ba00e",
          "grade": false,
          "grade_id": "cell-496203e8746296ca",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "2HqTPqrMvaRB"
      },
      "outputs": [],
      "source": [
        "# Create a fake review and find the 10 most similar reviews\n",
        "\n",
        "# YOUR CODE HERE\n",
        "# raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "33e150190aa62764e07f1f6c66bb9393",
          "grade": true,
          "grade_id": "cell-203092260fb65165",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4kKTC7lCvaRD"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert isinstance(fake_review, str), \"Did you write a review in the correct data type?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvjktC-kvaRD"
      },
      "source": [
        "## Part 3: Classification\n",
        "<a id=\"#p3\"></a>\n",
        "Your goal in this section will be to predict `stars` from the review dataset. \n",
        "\n",
        "1. Create a pipeline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier.\n",
        "    - Use that pipeline to train a model to predict the `stars` feature (i.e. the labels). \n",
        "    - Use that pipeline to predict a star rating for your fake review from Part 2. \n",
        "\n",
        "\n",
        "\n",
        "2. Create a parameter dict including `one parameter for the vectorizer` and `one parameter for the model`. \n",
        "    - Include 2 possible values for each parameter\n",
        "    - **Use `n_jobs` = 1** \n",
        "    - Due to limited computational resources on CodeGrader `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE.`\n",
        "    \n",
        "    \n",
        "3. Train the entire pipeline with a GridSearch\n",
        "    - Name your GridSearch object as `gs`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_vectors(docs):\n",
        "  return [nlp(doc).vector for doc in docs]"
      ],
      "metadata": {
        "id": "rB78x7b-q-vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "jupyter": {
          "outputs_hidden": true
        },
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b3492e82185541e6a463f46b16baff94",
          "grade": false,
          "grade_id": "cell-e2beb0252d274bba",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "G58tm-SOvaRD"
      },
      "outputs": [],
      "source": [
        "target = 'stars'\n",
        "y = df[target]\n",
        "X = df['text']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(oob_score=True)\n",
        "\n",
        "vect = TfidfVectorizer(stop_words = 'english')\n",
        "\n",
        "svd = TruncatedSVD(n_components=None, \n",
        "                   algorithm='randomized',\n",
        "                   n_iter=10)\n",
        "\n",
        "# instantiate a pipeline object\n",
        "pipe = Pipeline([(\"vect\", vect), # data transform\n",
        "                 (\"clf\", rfc)]) # estimator \n",
        "\n",
        "# a nice default starter set for hyper-parameter values\n",
        "# include more parameters and values to try to increase model performance \n",
        "params = {\n",
        "    #'vect__max_df':[.95,  1.0],\n",
        "    #'clf__n_estimators':[100, 300, 1000], \n",
        "    'clf__max_depth':(15, 20)\n",
        "}\n",
        "\n",
        "\n",
        "gs = GridSearchCV(pipe,\n",
        "                  param_grid=params, \n",
        "                  cv=3, \n",
        "                  n_jobs=1, \n",
        "                  verbose=1 )"
      ],
      "metadata": {
        "id": "aQXWyNEgkcTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfu9eMiyy4CK",
        "outputId": "2aadf81f-31f0-433a-a20b-bab26d84892f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('vect',\n",
              "                                        TfidfVectorizer(stop_words='english')),\n",
              "                                       ('clf',\n",
              "                                        RandomForestClassifier(oob_score=True))]),\n",
              "             n_jobs=1, param_grid={'clf__max_depth': (15, 20)}, verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ada8e7da1ec21f54451752e97b8cec3e",
          "grade": true,
          "grade_id": "cell-d07134c6fe5d056e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "AMODh91pvaRD"
      },
      "outputs": [],
      "source": [
        "# # Visible Testing\n",
        "prediction = gs.predict([\"This is your prediction statement.\"])[0]\n",
        "assert prediction in df.stars.values, 'You gs object should be able to accept raw text within a list. Did you include a vectorizer in your pipeline?'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2990aa9aa4e9c3cf665cee4392cdab92",
          "grade": false,
          "grade_id": "cell-00b8cbd0b1b4ece5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6JjFrrsEvaRE"
      },
      "source": [
        "## Part 4: Topic Modeling\n",
        "\n",
        "Let's find out what those yelp reviews are saying! :D\n",
        "\n",
        "1. Estimate a LDA topic model of the review text\n",
        "    - Set num_topics to `5`\n",
        "    - Name your LDA model `lda`\n",
        "2. Create 1-2 visualizations of the results\n",
        "    - You can use the most important 3 words of a topic in relevant visualizations. \n",
        "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
        "\n",
        "When you instantiate your LDA model, it should look like this: \n",
        "\n",
        "```python\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               random_state=723812,\n",
        "               num_topics = num_topics,\n",
        "               passes=1\n",
        "              )\n",
        "\n",
        "```\n",
        "\n",
        "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9b07079124654b07cce6d10dae1912b6",
          "grade": false,
          "grade_id": "cell-9eee6fe0eeebb9a3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "G20QEfC7vaRE"
      },
      "source": [
        "## Note about  pyLDAvis\n",
        "\n",
        "**pyLDAvis** is the Topic modeling package that we used in class to visualize the topics that LDA generates for us.\n",
        "\n",
        "You are welcomed to use pyLDAvis if you'd like for your visualization. However, **you MUST comment out the code that imports the package and the cell that generates the visualization before you submit your notebook to CodeGrade.** \n",
        "\n",
        "Although you should leave the print out of the visualization for graders to see (i.e. comment out the cell after you run it to create the viz). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "58830f560044227aa07c22d463e1596c",
          "grade": false,
          "grade_id": "cell-ec7b71ad284832d4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ye9WBp6hvaRE"
      },
      "source": [
        "### 1. Estimate a LDA topic model of the review text\n",
        "\n",
        "* Use the `tokenize` function you created earlier to create tokens.\n",
        "* Create an `id2word` object. \n",
        "> Hint: Use `corpora.Dictionary`\n",
        "* Create a `corpus` object.\n",
        "> Hint: Use `id2word.doc2bow`\n",
        "* Instantiate an `lda` model. \n",
        "\n",
        ">> Remember to read the LDA docs for more information on the various class attributes and methods available to you in the LDA model: https://radimrehurek.com/gensim/models/ldamodel.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bef17fce3f84cc31020898134cfdaec1",
          "grade": false,
          "grade_id": "cell-b4df1a20c7947a8b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "idq1kOTdvaRE"
      },
      "outputs": [],
      "source": [
        "# Do not change this value \n",
        "num_topics = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fb50f495592df233d97bd4199b958404",
          "grade": false,
          "grade_id": "cell-66331a185ff52f15",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUxtayGMvaRE",
        "outputId": "48ab902f-d4e0-4eee-fc5b-161e452a4c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.1 s, sys: 31 ms, total: 1.13 s\n",
            "Wall time: 1.14 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "id2word = corpora.Dictionary(df['tokens'] )\n",
        "corpus = [id2word.doc2bow(doc_lemmas) for doc_lemmas in df['tokens']]\n",
        "[(id2word[word_id], word_count) for word_id, word_count in corpus[num_topics]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "lda = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=num_topics, \n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           per_word_topics=True)\n",
        "lda.save('lda.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZR-rGeAe8m6",
        "outputId": "4e59b65c-1b18-44f5-eba8-ddbea88d0f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 59.2 s, sys: 673 ms, total: 59.9 s\n",
            "Wall time: 59.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyxCW7GfvaRF"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "073be746ce974f75f29c2c92f35af430",
          "grade": true,
          "grade_id": "cell-5a3c181311134fa9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "vXFPK1XzvaRF"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "\n",
        "assert lda.get_topics().shape[0] == 5, 'Did your model complete its training? Did you set num_topics to 5?'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk0nRY-jvaRF"
      },
      "source": [
        "\n",
        "#### 2. Create 1-2 visualizations of the results. Assign one of the visualizations to a variable called `visual_plot`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2cb1397c6a59aa5751d77bad34994f29",
          "grade": false,
          "grade_id": "cell-9b043e992fbd218c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "NR6Al7P-vaRF",
        "outputId": "193db38a-68ed-40ce-eac9-4c601eb04646"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "2      0.150359 -0.065924       1        1  39.262534\n",
              "0      0.177155  0.016521       2        1  22.007725\n",
              "4      0.144061  0.091670       3        1  16.674187\n",
              "3     -0.204412 -0.279078       4        1  14.216295\n",
              "1     -0.267163  0.236812       5        1   7.839258, topic_info=           Term         Freq        Total Category  logprob  loglift\n",
              "90          not  7125.000000  7125.000000  Default  30.0000  30.0000\n",
              "137        food  4633.000000  4633.000000  Default  29.0000  29.0000\n",
              "1115    chicken  1361.000000  1361.000000  Default  28.0000  28.0000\n",
              "99         room  1195.000000  1195.000000  Default  27.0000  27.0000\n",
              "196       great  4131.000000  4131.000000  Default  26.0000  26.0000\n",
              "...         ...          ...          ...      ...      ...      ...\n",
              "350       light   139.276142   314.796895   Topic5  -5.6207   1.7306\n",
              "282        shop   146.741864   516.354376   Topic5  -5.5685   1.2879\n",
              "2296  available   127.257426   252.864426   Topic5  -5.7109   1.8594\n",
              "194         fun   128.070342   436.461571   Topic5  -5.7046   1.3199\n",
              "42      parking   126.929455   364.042926   Topic5  -5.7135   1.4924\n",
              "\n",
              "[312 rows x 6 columns], token_table=      Topic      Freq     Term\n",
              "term                          \n",
              "181       1  0.777375  amazing\n",
              "181       3  0.218748  amazing\n",
              "181       4  0.003563  amazing\n",
              "389       1  0.180379      ask\n",
              "389       2  0.819651      ask\n",
              "...     ...       ...      ...\n",
              "671       2  0.066871    worth\n",
              "671       3  0.024637    worth\n",
              "308       1  0.993217      wow\n",
              "113       1  0.237481     year\n",
              "113       3  0.761464     year\n",
              "\n",
              "[441 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 1, 5, 4, 2])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el54321397981227620648444218515\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el54321397981227620648444218515_data = {\"mdsDat\": {\"x\": [0.15035932532179858, 0.1771550428987727, 0.14406088507431544, -0.20441196448316992, -0.26716328881171697], \"y\": [-0.06592431065084181, 0.01652057238140527, 0.09167028948918875, -0.27907844008061883, 0.23681188886086682], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [39.262534282904255, 22.00772500362324, 16.674187228506923, 14.216295454410114, 7.839258030555471]}, \"tinfo\": {\"Term\": [\"not\", \"food\", \"chicken\", \"room\", \"great\", \"tell\", \"place\", \"good\", \"say\", \"cheese\", \"order\", \"sauce\", \"taste\", \"ask\", \"fry\", \"coffee\", \"flavor\", \"cream\", \"dish\", \"hotel\", \"time\", \"recommend\", \"fresh\", \"delicious\", \"vegas\", \"year\", \"go\", \"car\", \"staff\", \"new\", \"food\", \"pizza\", \"server\", \"meat\", \"beer\", \"taco\", \"sushi\", \"waitress\", \"wine\", \"spot\", \"atmosphere\", \"decent\", \"waiter\", \"green\", \"mexican\", \"drink\", \"decor\", \"salsa\", \"glad\", \"cocktail\", \"patio\", \"dining\", \"attentive\", \"birthday\", \"bartender\", \"average\", \"onion\", \"french\", \"pricey\", \"entree\", \"table\", \"wow\", \"restaurant\", \"bar\", \"pretty\", \"place\", \"seat\", \"breakfast\", \"dinner\", \"love\", \"good\", \"great\", \"definitely\", \"favorite\", \"nice\", \"worth\", \"enjoy\", \"amazing\", \"price\", \"service\", \"come\", \"friend\", \"friendly\", \"not\", \"little\", \"like\", \"time\", \"order\", \"try\", \"eat\", \"have\", \"menu\", \"get\", \"go\", \"staff\", \"be\", \"tell\", \"charge\", \"money\", \"manager\", \"hair\", \"rude\", \"later\", \"phone\", \"card\", \"horrible\", \"tire\", \"dollar\", \"waste\", \"speak\", \"save\", \"window\", \"future\", \"clearly\", \"hold\", \"attitude\", \"bill\", \"state\", \"send\", \"bother\", \"gift\", \"awful\", \"realize\", \"clear\", \"hurt\", \"sorry\", \"owner\", \"say\", \"call\", \"leave\", \"ask\", \"pay\", \"minute\", \"update\", \"not\", \"lady\", \"know\", \"bad\", \"review\", \"customer\", \"guy\", \"talk\", \"take\", \"want\", \"let\", \"hour\", \"go\", \"s\", \"start\", \"people\", \"get\", \"time\", \"wait\", \"give\", \"come\", \"day\", \"like\", \"think\", \"service\", \"car\", \"job\", \"nail\", \"fix\", \"professional\", \"office\", \"purchase\", \"issue\", \"pool\", \"salon\", \"dr\", \"product\", \"class\", \"repair\", \"pedicure\", \"gel\", \"patient\", \"result\", \"honest\", \"knowledgeable\", \"team\", \"process\", \"situation\", \"massage\", \"schedule\", \"efficient\", \"doctor\", \"garage\", \"polish\", \"wedding\", \"paul\", \"company\", \"year\", \"dog\", \"store\", \"thank\", \"week\", \"work\", \"shop\", \"new\", \"help\", \"need\", \"recommend\", \"care\", \"clean\", \"home\", \"find\", \"staff\", \"look\", \"great\", \"feel\", \"service\", \"experience\", \"time\", \"good\", \"day\", \"price\", \"have\", \"friendly\", \"chicken\", \"cheese\", \"sauce\", \"fry\", \"flavor\", \"cream\", \"soup\", \"rice\", \"beef\", \"bread\", \"egg\", \"noodle\", \"spicy\", \"shrimp\", \"potato\", \"grill\", \"pork\", \"bowl\", \"thai\", \"veggie\", \"raman\", \"bean\", \"bacon\", \"bbq\", \"cookie\", \"salmon\", \"plenty\", \"butter\", \"tender\", \"crispy\", \"salad\", \"dish\", \"taste\", \"dessert\", \"ice\", \"sweet\", \"fresh\", \"fish\", \"steak\", \"order\", \"delicious\", \"try\", \"like\", \"good\", \"eat\", \"meal\", \"coffee\", \"hotel\", \"chocolate\", \"donut\", \"downtown\", \"casino\", \"brunch\", \"locate\", \"la\", \"cafe\", \"de\", \"toronto\", \"boba\", \"curry\", \"milk\", \"suite\", \"mac\", \"movie\", \"strawberry\", \"bagel\", \"indian\", \"pour\", \"japanese\", \"heavy\", \"typical\", \"vanilla\", \"modern\", \"dance\", \"wifi\", \"spacious\", \"club\", \"room\", \"bed\", \"view\", \"rock\", \"stay\", \"tea\", \"strip\", \"bathroom\", \"free\", \"vegas\", \"floor\", \"cool\", \"light\", \"shop\", \"available\", \"fun\", \"parking\"], \"Freq\": [7125.0, 4633.0, 1361.0, 1195.0, 4131.0, 1513.0, 5031.0, 6026.0, 1525.0, 934.0, 3225.0, 867.0, 1161.0, 1446.0, 815.0, 592.0, 754.0, 709.0, 827.0, 523.0, 4242.0, 1351.0, 997.0, 1164.0, 982.0, 917.0, 2991.0, 666.0, 1510.0, 1099.0, 4633.097321128797, 814.9139899249549, 801.3756330471737, 644.8769822458961, 595.9205504873605, 593.1210851296751, 507.44535664523625, 502.7674596280461, 485.0322811698977, 487.20503468300535, 394.3314688747819, 378.04211737724097, 349.28491282486874, 323.5024933205519, 285.0766096188632, 1252.7716433915386, 264.2036570910497, 261.2842031166303, 275.786526839275, 258.4831684011027, 256.3689743549063, 247.96051197226222, 246.52351825436648, 233.97634537031166, 224.95251535834905, 199.53476977776046, 196.60583239809475, 187.41078544554975, 178.40224546284955, 175.31002760940333, 1009.6398213057028, 180.42245739369682, 1605.9504244750397, 1084.371386264288, 971.5675587646539, 4482.71302299706, 625.3587890850479, 467.0933552250382, 655.7807908558078, 1886.6897101478646, 4745.256725459635, 3327.3621821808742, 1133.155188660183, 529.1450020455173, 1388.5071070363647, 515.9570155157029, 762.5136696399372, 1091.0277951325188, 1294.1837684535305, 2299.6013894206185, 2370.9890563666663, 792.3731687212625, 1029.759078520108, 3285.7941077881646, 1052.0658412113373, 1973.9707571884724, 2175.4546021480337, 1785.8752384969794, 1460.1999468245244, 1010.1152918930894, 1337.2193269450697, 886.1639120912545, 1289.8212226850287, 1311.6182579491162, 914.9036967715784, 917.6802943435634, 1512.2451361192948, 568.472188002755, 461.75101452306376, 452.99515091151875, 368.3092592181857, 333.2037945790976, 334.8351766236752, 281.30684975895457, 242.75152820937925, 236.54227838459389, 214.1087331851746, 201.51314379633666, 191.9556387174631, 191.22037448564478, 182.87873397839473, 181.02641702705748, 176.0151368130159, 160.0956087075211, 158.98137092566867, 149.30467082998067, 145.4134970401587, 143.76293823272826, 133.94223648204004, 133.4676932848922, 131.89408029590717, 128.02428243898993, 129.2514821613954, 127.91818190899896, 121.49928206149187, 119.42251153131193, 579.6175315591781, 1423.4621026524192, 715.0563472449556, 787.2544717154253, 1185.686831303169, 668.9848153920776, 849.0167677216537, 162.2866606802852, 3831.0099260095935, 248.72789220900853, 1083.3999386493235, 843.7719356480974, 634.723153451885, 678.32422563523, 496.6139169887673, 314.2746205740813, 870.9373910648475, 990.1271801379214, 431.58694675711, 619.9352302883099, 1364.014238342211, 802.347765349068, 511.31658775444373, 786.4544764839642, 1168.1422296294738, 1473.6556583171414, 732.5174558567934, 554.8212483227123, 1030.9304053477747, 645.0459822755153, 815.9075211554149, 516.4035319849576, 520.2846775593428, 665.8785126608176, 509.21601258136474, 380.1109755324545, 380.68175058889403, 360.1509485771111, 315.835656330632, 308.77117722746294, 312.278452273176, 301.00881545786797, 266.2588516819183, 254.58744056502164, 257.4716502925689, 236.682558000358, 214.00037161873843, 207.7668811286329, 178.4283120018397, 168.75988831026663, 169.69151568269766, 172.3419235772241, 168.7813299835018, 150.17568935928736, 145.41768495247698, 147.29841104298134, 142.71855723470702, 141.65973656176595, 137.79167584824643, 125.14985763641127, 129.43684027740596, 120.07748326207033, 119.13004122745298, 121.98910554691224, 310.4328307338342, 699.4552589148383, 335.14374978253034, 580.4410617541049, 409.3503340752732, 437.2463698856748, 781.2582509964973, 369.0086447038642, 639.4907062348904, 426.7643241938184, 710.9490621398484, 699.1328340380907, 398.15016371108584, 485.5366741402785, 434.2528761770471, 605.6158712128205, 594.8425919948019, 611.2056735320838, 803.6839561198535, 464.6049547321427, 742.7206708663372, 449.92605378776585, 592.8682823313719, 638.1512300548654, 433.3473748931406, 440.46932377412827, 459.8620413786528, 367.2055256642212, 1360.8519088448702, 933.8466849433075, 866.4182928314428, 814.7593104870946, 753.391904738258, 709.0870230873849, 539.8111032709108, 524.6117496299845, 460.4630635483226, 431.4577726802524, 393.23527560312874, 392.44987359868793, 390.5779360446936, 381.7542750768269, 329.4532165279221, 305.7919258454343, 277.2810343042872, 270.62481076396415, 252.0528523358189, 245.07050902405547, 241.48525342953195, 226.3959430907823, 224.38650823284374, 224.3759065396715, 224.41738789657052, 218.40695845932845, 222.24050148675076, 195.06586164015263, 194.2771151505763, 189.94040569927373, 583.8296255585806, 682.3721200639998, 783.8030807802274, 433.82199896375414, 423.9397272736789, 457.7936773492538, 595.1609360220218, 300.9103413182462, 343.60152512660665, 981.5885933086697, 552.3391874104591, 568.6403378437902, 565.724791044603, 642.3412306504563, 400.7578019703692, 359.44691640108493, 591.3178249735603, 522.3084211186153, 313.3768807117761, 294.43546416650435, 207.64821690643493, 197.81339627569386, 165.16795835221856, 159.27150647756335, 158.3989832934535, 148.29155512160693, 133.8004365414685, 132.31842735437272, 124.30313000923907, 126.037352649472, 121.03308393134922, 114.78916263517061, 118.720261856827, 110.24915037875915, 105.95403727791228, 107.11514844519245, 99.46442004222298, 97.57829815240262, 95.56323155274505, 97.06406811780295, 88.13997153744093, 90.71981471281745, 81.99196870416559, 80.41826669486935, 80.5874176597839, 80.48031736374956, 137.07327583948398, 912.0689500590132, 168.1721561236017, 173.7629115418172, 165.21956130351353, 342.80205812504914, 212.80462659511755, 205.50375796550975, 141.44617833030347, 248.04319339482325, 302.54291091789736, 149.07665588736222, 149.93934013263217, 139.276141729446, 146.74186406223663, 127.2574258287627, 128.07034241160224, 126.92945523234695], \"Total\": [7125.0, 4633.0, 1361.0, 1195.0, 4131.0, 1513.0, 5031.0, 6026.0, 1525.0, 934.0, 3225.0, 867.0, 1161.0, 1446.0, 815.0, 592.0, 754.0, 709.0, 827.0, 523.0, 4242.0, 1351.0, 997.0, 1164.0, 982.0, 917.0, 2991.0, 666.0, 1510.0, 1099.0, 4633.8800163876, 815.6976497418896, 802.158055885233, 645.6663762174873, 596.7020608073266, 593.9075424481871, 508.22789690775295, 503.5525009783682, 485.81805538391563, 488.0080627801215, 395.11663251084474, 378.83876991190334, 350.06936412922516, 324.29754797231976, 285.8575458812868, 1256.271313807067, 264.99351605098644, 262.0685429394827, 276.6232916744087, 259.2739463765077, 257.15798214029644, 248.7475752636875, 247.31027692801175, 234.77590001306444, 225.73690971321193, 200.32377973940166, 197.3955114082826, 188.2067533048406, 179.18978515882793, 176.0918739822037, 1021.2055967960297, 181.22918859791403, 1651.044906435476, 1131.74757383205, 1021.0391356471588, 5031.285160602538, 656.1261915515267, 488.5500042803095, 702.9587002158436, 2203.840264227242, 6026.150748613994, 4131.643834820151, 1313.2848134117062, 577.2570757772785, 1731.5773962618964, 568.2547853156399, 903.068994707333, 1403.4411731967407, 1735.2527927397407, 3578.5004232461056, 3725.328524087687, 955.4037512855209, 1397.5631234435007, 7125.467771060008, 1455.6967974687375, 3613.438664099143, 4242.373705120775, 3225.0158866042075, 2458.529724507842, 1411.4588749623426, 2245.157740936148, 1174.9848558031297, 2846.916842904538, 2991.1524148724766, 1510.3444635639194, 1619.204614776468, 1513.0283510686752, 569.2587611268544, 462.53343074044136, 453.7749858732357, 369.0870010311467, 333.97775479962564, 335.61829240614986, 282.0808947726601, 243.54015700540302, 237.3195917122638, 214.89336438045996, 202.30570068788361, 192.73533170596616, 192.0003892066619, 183.66563316065435, 181.81146550575585, 176.813777757998, 160.8864633595022, 159.76839829079486, 150.08523679532274, 146.19433935366797, 144.55128123236608, 134.72271279140634, 134.25136379049138, 132.6908049482276, 128.80770486113988, 130.04907389388185, 128.71042638262952, 122.29656284765203, 120.21168626923924, 597.6656650824594, 1525.8082791296058, 763.6484635898757, 921.4990167581796, 1446.9570075858803, 831.8257029256258, 1100.2551395740243, 168.57300087189145, 7125.467771060008, 278.7122559500553, 1700.6127673030594, 1258.5851106495509, 889.201163133908, 987.9571970724152, 668.7634202929011, 375.30195477518697, 1457.0579549356066, 1728.9869615127438, 572.9181125110654, 981.7965073776211, 2991.1524148724766, 1429.6086739005482, 766.7763091472762, 1478.7541776295136, 2846.916842904538, 4242.373705120775, 1567.9915581302776, 948.2052880021456, 3725.328524087687, 1482.5650335061675, 3613.438664099143, 1406.3100719552763, 3578.5004232461056, 666.669366559753, 510.01428373621303, 380.8971358101086, 381.48503300623526, 360.93620378298056, 316.6274924292836, 309.5728956052568, 313.1001049475398, 301.8132464626775, 267.0453365128666, 255.37368172439375, 258.27791679830057, 237.47161990285824, 214.78960475248064, 208.5560259122386, 179.22900699475798, 169.5459729529857, 170.48904182258119, 173.1566411772797, 169.57997198400983, 150.96474789533787, 146.2101101240015, 148.10963823807558, 143.50610522426763, 142.45405822455234, 138.63919781276277, 125.93496819068115, 130.2560165257995, 120.87205478514667, 119.9276872107199, 122.91291680199288, 355.386646315938, 917.9686900939113, 397.8653759350666, 819.412241842573, 533.0179549900145, 617.6645706007622, 1409.4562628579774, 516.3543761966752, 1099.137393895101, 654.5099269016797, 1351.4801287477321, 1351.0991732586963, 650.4857440275067, 933.7937592301989, 828.3731876205251, 1481.8127375106383, 1510.3444635639194, 1872.173227383722, 4131.643834820151, 1102.6131683479707, 3578.5004232461056, 1430.4248900457687, 4242.373705120775, 6026.150748613994, 1482.5650335061675, 1735.2527927397407, 2245.157740936148, 1397.5631234435007, 1361.6351526986637, 934.6323870531644, 867.1997186890097, 815.544802738233, 754.175958287069, 709.8739572573407, 540.5925836479962, 525.39436464357, 461.24510033951964, 432.242075055227, 394.0186708667562, 393.23315838424645, 391.3609086104403, 382.5365463945706, 330.23604738839106, 306.58289062113914, 278.06094319466445, 271.4123038835107, 252.83899623712358, 245.8559423014247, 242.26868135142564, 227.18218767070545, 225.17127729448347, 225.1625198968768, 225.20463161626566, 219.19502139234683, 223.0716810787209, 195.85327401684032, 195.06505789910264, 190.72118859885336, 688.5842798236968, 827.6666185613927, 1161.2082217987934, 554.661424859329, 548.8363366301651, 654.9464181287693, 997.7194305952183, 353.3692127706222, 478.12576685251594, 3225.0158866042075, 1164.248910568252, 2458.529724507842, 3613.438664099143, 6026.150748613994, 1411.4588749623426, 899.5620900801752, 592.1034649615123, 523.0919402891521, 314.1744230029929, 295.2217238662269, 208.45285303324647, 198.59620180262976, 165.96495388121656, 160.0598156451707, 159.19102481092133, 149.07806929857307, 134.6103412842902, 133.12416854370585, 125.09051975773986, 126.85625821000818, 121.82022453935774, 115.57386651432914, 119.54841946760135, 111.03689541788964, 106.75476299182863, 107.9274156820467, 100.26676674873234, 98.3727733171229, 96.37599039727395, 97.89376805707349, 88.94837709894279, 91.5659736652632, 82.78154826158163, 81.20070028378217, 81.37248280177369, 81.26993124845991, 144.0748472683061, 1195.0301546866697, 197.39540357550857, 208.03796376779343, 214.6706302812315, 651.6109788493586, 332.46005010521776, 352.31953256066987, 191.25994820030763, 648.5963264042232, 982.5126040679224, 261.1521640495026, 379.19961157638886, 314.79689525400033, 516.3543761966752, 252.86442578826643, 436.4615705834559, 364.0429264659715], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.7273, -5.4652, -5.4819, -5.6992, -5.7782, -5.7829, -5.9389, -5.9481, -5.9841, -5.9796, -6.1911, -6.2333, -6.3124, -6.3891, -6.5155, -5.0352, -6.5916, -6.6027, -6.5486, -6.6134, -6.6217, -6.655, -6.6608, -6.7131, -6.7524, -6.8723, -6.8871, -6.935, -6.9842, -7.0017, -5.2509, -6.973, -4.7868, -5.1795, -5.2894, -3.7603, -5.7299, -6.0217, -5.6824, -4.6257, -3.7034, -4.0583, -5.1355, -5.897, -4.9323, -5.9222, -5.5317, -5.1734, -5.0026, -4.4278, -4.3972, -5.4932, -5.2312, -4.0709, -5.2098, -4.5805, -4.4833, -4.6806, -4.8819, -5.2505, -4.9699, -5.3814, -5.006, -4.9893, -5.3495, -5.3464, -4.268, -5.2464, -5.4544, -5.4735, -5.6805, -5.7806, -5.7758, -5.9499, -6.0974, -6.1233, -6.2229, -6.2835, -6.3321, -6.336, -6.3806, -6.3908, -6.4188, -6.5136, -6.5206, -6.5834, -6.6098, -6.6212, -6.692, -6.6955, -6.7074, -6.7372, -6.7276, -6.738, -6.7895, -6.8067, -5.227, -4.3285, -5.017, -4.9208, -4.5113, -5.0836, -4.8453, -6.5, -3.3385, -6.073, -4.6015, -4.8515, -5.1362, -5.0698, -5.3816, -5.8391, -4.8198, -4.6916, -5.5219, -5.1598, -4.3712, -4.9019, -5.3524, -4.9219, -4.5262, -4.2939, -4.9929, -5.2707, -4.6512, -5.1201, -4.8851, -5.3425, -5.335, -4.8108, -5.079, -5.3714, -5.3699, -5.4253, -5.5566, -5.5793, -5.568, -5.6047, -5.7274, -5.7722, -5.761, -5.8451, -5.9459, -5.9754, -6.1277, -6.1834, -6.1779, -6.1624, -6.1833, -6.3001, -6.3323, -6.3194, -6.351, -6.3584, -6.3861, -6.4824, -6.4487, -6.5237, -6.5316, -6.5079, -5.5739, -4.7616, -5.4973, -4.9481, -5.2973, -5.2314, -4.651, -5.401, -4.8512, -5.2556, -4.7453, -4.762, -5.325, -5.1266, -5.2382, -4.9056, -4.9236, -4.8964, -4.6227, -5.1707, -4.7015, -5.2028, -4.9269, -4.8533, -5.2403, -5.224, -5.1809, -5.4059, -3.9365, -4.3131, -4.388, -4.4495, -4.5278, -4.5884, -4.8612, -4.8897, -5.0202, -5.0852, -5.178, -5.18, -5.1848, -5.2076, -5.355, -5.4295, -5.5274, -5.5517, -5.6228, -5.6508, -5.6656, -5.7301, -5.739, -5.7391, -5.7389, -5.766, -5.7486, -5.8791, -5.8831, -5.9057, -4.7828, -4.6268, -4.4882, -5.0798, -5.1028, -5.026, -4.7636, -5.4456, -5.3129, -4.2632, -4.8382, -4.8091, -4.8143, -4.6873, -5.159, -5.2678, -4.1748, -4.2989, -4.8097, -4.8721, -5.2213, -5.2698, -5.4502, -5.4865, -5.492, -5.558, -5.6608, -5.6719, -5.7344, -5.7206, -5.7611, -5.814, -5.7804, -5.8544, -5.8941, -5.8832, -5.9573, -5.9765, -5.9974, -5.9818, -6.0782, -6.0494, -6.1505, -6.1699, -6.1678, -6.1691, -5.6366, -3.7414, -5.4322, -5.3995, -5.4499, -4.72, -5.1968, -5.2317, -5.6052, -5.0435, -4.8449, -5.5527, -5.5469, -5.6207, -5.5685, -5.7109, -5.7046, -5.7135], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9347, 0.9339, 0.9339, 0.9337, 0.9336, 0.9336, 0.9334, 0.9333, 0.9333, 0.9333, 0.9329, 0.9328, 0.9327, 0.9324, 0.9322, 0.9321, 0.9319, 0.9319, 0.9319, 0.9318, 0.9318, 0.9317, 0.9317, 0.9315, 0.9314, 0.931, 0.9309, 0.9307, 0.9305, 0.9304, 0.9235, 0.9304, 0.9072, 0.8921, 0.8852, 0.8195, 0.8869, 0.89, 0.8654, 0.7795, 0.6959, 0.7184, 0.7874, 0.8479, 0.7141, 0.8384, 0.7657, 0.6831, 0.6416, 0.4927, 0.4831, 0.7478, 0.6295, 0.1608, 0.6102, 0.3303, 0.267, 0.3439, 0.4139, 0.6003, 0.4167, 0.6528, 0.1432, 0.1105, 0.4336, 0.3671, 1.5133, 1.5124, 1.5121, 1.5121, 1.5117, 1.5115, 1.5114, 1.511, 1.5105, 1.5105, 1.5101, 1.5099, 1.5097, 1.5097, 1.5095, 1.5094, 1.5092, 1.5088, 1.5088, 1.5086, 1.5084, 1.5083, 1.508, 1.5079, 1.5078, 1.5077, 1.5076, 1.5076, 1.5072, 1.5072, 1.4831, 1.4443, 1.448, 1.3563, 1.3146, 1.2959, 1.2546, 1.4758, 0.8932, 1.4, 1.0629, 1.1139, 1.1766, 1.1378, 1.2162, 1.3363, 0.9992, 0.9563, 1.2305, 1.054, 0.7285, 0.9362, 1.1086, 0.8824, 0.623, 0.4564, 0.7527, 0.9779, 0.2291, 0.6816, 0.0257, 0.5119, -0.4145, 1.7901, 1.7897, 1.7892, 1.7892, 1.7891, 1.7888, 1.7887, 1.7887, 1.7886, 1.7884, 1.7882, 1.7882, 1.788, 1.7876, 1.7875, 1.7868, 1.7867, 1.7866, 1.7866, 1.7866, 1.7861, 1.7859, 1.7858, 1.7858, 1.7857, 1.7852, 1.7851, 1.785, 1.7847, 1.7846, 1.7838, 1.6561, 1.5194, 1.6198, 1.4465, 1.5273, 1.4459, 1.2013, 1.4553, 1.2497, 1.3637, 1.149, 1.1325, 1.3004, 1.1373, 1.1455, 0.8965, 0.8595, 0.6719, 0.1541, 0.9271, 0.2189, 0.6347, -0.1766, -0.454, 0.5613, 0.4202, 0.2057, 0.4547, 1.9502, 1.9499, 1.9499, 1.9498, 1.9497, 1.9497, 1.9493, 1.9493, 1.9491, 1.949, 1.9488, 1.9488, 1.9488, 1.9487, 1.9484, 1.9482, 1.948, 1.9479, 1.9477, 1.9476, 1.9475, 1.9473, 1.9473, 1.9473, 1.9473, 1.9472, 1.947, 1.9468, 1.9467, 1.9467, 1.7858, 1.7577, 1.5577, 1.7051, 1.6926, 1.5926, 1.4341, 1.7901, 1.6204, 0.7613, 1.2051, 0.4867, 0.0965, -0.288, 0.6918, 1.0334, 2.5447, 2.5445, 2.5435, 2.5434, 2.5422, 2.5421, 2.5412, 2.5411, 2.541, 2.5407, 2.54, 2.54, 2.5397, 2.5395, 2.5395, 2.5392, 2.5391, 2.5389, 2.5385, 2.5385, 2.538, 2.5379, 2.5376, 2.5375, 2.5369, 2.5367, 2.5364, 2.5363, 2.5363, 2.5363, 2.4962, 2.2758, 2.3858, 2.366, 2.2842, 1.9037, 2.0999, 2.007, 2.2443, 1.5848, 1.3681, 1.9854, 1.6182, 1.7306, 1.2879, 1.8594, 1.3199, 1.4924]}, \"token.table\": {\"Topic\": [1, 3, 4, 1, 2, 1, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 5, 1, 5, 1, 3, 5, 4, 1, 2, 3, 4, 4, 3, 5, 4, 1, 2, 1, 5, 2, 4, 4, 1, 5, 5, 4, 5, 2, 3, 3, 2, 1, 2, 3, 5, 2, 4, 4, 5, 3, 1, 3, 2, 2, 2, 5, 1, 5, 1, 2, 3, 4, 2, 3, 4, 1, 3, 5, 4, 4, 5, 1, 2, 3, 5, 1, 2, 3, 5, 1, 1, 1, 3, 4, 1, 4, 1, 4, 1, 1, 4, 1, 4, 3, 1, 3, 2, 5, 5, 3, 1, 5, 1, 4, 3, 4, 1, 4, 5, 1, 1, 2, 3, 1, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 4, 3, 4, 2, 5, 1, 1, 2, 3, 5, 1, 1, 4, 1, 2, 3, 1, 3, 4, 1, 5, 2, 3, 3, 1, 2, 3, 4, 2, 1, 2, 3, 1, 1, 2, 3, 1, 3, 4, 1, 3, 1, 4, 2, 3, 2, 1, 2, 3, 4, 5, 2, 3, 4, 2, 1, 2, 3, 4, 3, 2, 5, 1, 2, 2, 4, 5, 5, 3, 5, 3, 1, 2, 3, 3, 5, 1, 2, 2, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 5, 1, 2, 3, 1, 3, 4, 5, 2, 3, 1, 4, 1, 1, 4, 1, 5, 1, 2, 5, 2, 5, 3, 1, 2, 3, 1, 3, 1, 3, 4, 5, 4, 1, 2, 4, 3, 1, 1, 2, 4, 2, 5, 1, 2, 3, 5, 3, 1, 3, 1, 2, 3, 1, 2, 3, 2, 1, 1, 2, 3, 4, 3, 3, 4, 4, 5, 1, 2, 5, 1, 3, 1, 3, 3, 3, 3, 4, 2, 1, 3, 3, 1, 4, 5, 3, 1, 2, 3, 4, 4, 5, 2, 3, 5, 2, 1, 2, 3, 5, 1, 4, 4, 3, 1, 4, 2, 1, 2, 4, 3, 1, 2, 2, 1, 1, 2, 3, 5, 3, 5, 4, 3, 2, 4, 5, 2, 4, 1, 1, 3, 1, 2, 3, 4, 2, 2, 3, 5, 1, 4, 2, 3, 5, 5, 1, 5, 5, 1, 1, 4, 5, 1, 5, 1, 1, 2, 3, 1, 2, 1, 4, 1, 5, 3, 2, 4, 4, 1, 2, 3, 1, 2, 4, 1, 2, 3, 2, 5, 1, 2, 4, 5, 1, 2, 5, 1, 3, 5, 4, 1, 5, 1, 2, 1, 1, 1, 2, 3, 2, 3, 1, 3, 5, 2, 1, 1, 2, 3, 1, 2, 3, 1, 1, 3], \"Freq\": [0.7773749415623413, 0.2187480358016854, 0.003562671592861326, 0.18037854520325755, 0.8196511670921972, 0.9971739167147966, 0.9987453941184091, 0.9927691969010735, 0.37174070534820897, 0.12655002735258178, 0.5022454210555589, 0.9983837178999775, 0.9937293746363184, 0.9947982828513618, 0.32894080543058085, 0.6705942989937446, 0.9914070426296608, 0.9578107566244841, 0.04152869516729774, 0.9967355373379208, 0.2561958238568695, 0.7372165543636449, 0.9948369742112976, 0.5669450245031141, 0.3094111735033335, 0.1198119114963008, 0.00432311020862941, 0.9947963012293067, 0.14691324861020277, 0.8510836471211747, 0.9973005667949576, 0.9988234315692212, 0.9918304678625164, 0.996695146252144, 0.9912821550357945, 0.9906789491357106, 0.9984808946476957, 0.9971264364880066, 0.9558898698362409, 0.042984341041886635, 0.9941857973105142, 0.9956432997042115, 0.9927684246003085, 0.9362946880542631, 0.06285614689035612, 0.9989959542265948, 0.9977820618494919, 0.0737910099348315, 0.31207447951605816, 0.611850457376311, 0.99699791941025, 0.9977887716223064, 0.9993233841862058, 0.9995335367940488, 0.9962618758339162, 0.9980139946699688, 0.4797633262930803, 0.5204575370054398, 0.994480428644393, 0.9944901308600378, 0.041645020721947305, 0.9508946398177968, 0.9950864851856047, 0.998136364627449, 0.6364539354500675, 0.2767541153306704, 0.07328212753178762, 0.01342163507908198, 0.12380881627410416, 0.8722893873857338, 0.9946509465297398, 0.5142410330784786, 0.08966253910086293, 0.3955700254449835, 0.9987688557265612, 0.9962186236141268, 0.9932501697425865, 0.09514582238840658, 0.6862645487163793, 0.21863295357335977, 0.9852131782166172, 0.2725006936421311, 0.4350568004930063, 0.2920613869976306, 0.9954658663036803, 0.9977859448965627, 0.996250791091827, 0.862722227828589, 0.12640060884337667, 0.009898842861228295, 0.5248018653517831, 0.47412541681535886, 0.2163481984175011, 0.7824593176099623, 0.9969946430115146, 0.933198493451429, 0.0668602579149652, 0.1751913110281426, 0.8240032698013326, 0.9925757857081801, 0.15583160473385518, 0.8419933481587337, 0.9984889170851629, 0.9958616735576664, 0.997827551762152, 0.9985367257821147, 0.9973960132885997, 0.0023880191858466075, 0.715571681128114, 0.2841032120122512, 0.9953894870797937, 0.9974146634612128, 0.8448966850503746, 0.04650807440644264, 0.1085188402816995, 0.9937994073348663, 0.48377234262042124, 0.2013387784316204, 0.31459184129940687, 0.9164027990262394, 0.08315186078120887, 0.43714333715256964, 0.11518092078501317, 0.4217254186222923, 0.026301155139884895, 0.5149098672763449, 0.05938672125860858, 0.40895855775814544, 0.01687122763028653, 0.147154868394701, 0.8518002959000961, 0.9987285660923234, 0.9984407375040967, 0.42503955655125053, 0.5705485939291561, 0.9998100908127772, 0.24206119215999575, 0.20814178943693903, 0.16805522258241742, 0.3823641761508213, 0.9935881508837996, 0.40291888448055513, 0.5963600404625131, 0.8289689033922497, 0.11304121409894315, 0.05652060704947157, 0.7369971221494096, 0.2625999454648867, 0.9993319769356585, 0.7056749568771192, 0.29326751454633526, 0.995397543289235, 0.9903573242964118, 0.9931428120070211, 0.4531217703864826, 0.4102683936522571, 0.0832479531640282, 0.0533910923246088, 0.994793874763989, 0.29002158443918924, 0.5853162885954546, 0.12444562532299755, 0.9977467852738073, 0.43862692969991474, 0.45601153362094793, 0.10531058144472039, 0.7874014769861745, 0.10587189511426329, 0.10653566875134331, 0.8052484998733738, 0.19459566994234823, 0.9990824846682308, 0.9980987503250485, 0.7431626565076285, 0.2571911004412718, 0.9970548921308259, 0.5955038149981036, 0.18885087326791017, 0.20488538137556292, 0.0106896720717685, 0.9908700208929295, 0.32696219141095934, 0.6523965221143908, 0.019862189197862014, 0.9951905489507612, 0.24626581720490415, 0.11347542557480877, 0.523918454249649, 0.1146826109532642, 0.9933202609532283, 0.9986533277343099, 0.9979125270243152, 0.3676933023160076, 0.6314954222601792, 0.9893982069695025, 0.7725436012552384, 0.22593256263124895, 0.9873660357284, 0.9964864114378877, 0.9960987130121924, 0.9980112640595422, 0.25343805967275396, 0.636829277553579, 0.10878431795698255, 0.9965799499951297, 0.9925182665773025, 0.10404996328972611, 0.8933945123842, 0.9981577511710785, 0.11828553044306053, 0.8540432335659509, 0.02712970881721572, 0.24610846981605372, 0.7540344607130156, 0.10165284500083822, 0.45426115109749576, 0.44155454547239104, 0.5462940383110482, 0.22582367541125398, 0.07140013266679353, 0.15663750034653154, 0.7226779655140326, 0.04396519942290693, 0.03159998708521435, 0.15525211046214007, 0.04671302438683861, 0.9933786276030697, 0.47271266731911754, 0.2003019776775922, 0.3263586889626902, 0.856232654711779, 0.13204223769005177, 0.01134383485309723, 0.9954125745029195, 0.9982921361966562, 0.9964732843701897, 0.6002920820639202, 0.3990830693721247, 0.9989679248571204, 0.7540522719285588, 0.24510954211673244, 0.9970000936003175, 0.9932669263871473, 0.2281289048076407, 0.7716392039111034, 0.9905589074136181, 0.9988467195990841, 0.9906617038058633, 0.9976446769330504, 0.19164173744825, 0.28191313501074616, 0.526089866122416, 0.4176002040776768, 0.5813649899904912, 0.8021587732656666, 0.16458981308906767, 0.002887540580509959, 0.030607930153405568, 0.9968640528959629, 0.4611627061659089, 0.5376489127576375, 0.001122733307768494, 0.9980181997953833, 0.9979963505478878, 0.5537957215710262, 0.14170472830792777, 0.3044946240664881, 0.9704422286329228, 0.02844399635648222, 0.20601966017601098, 0.027469288023468128, 0.4175331779567156, 0.34885995789804525, 0.9967797940377087, 0.995497000984925, 0.9925726536661436, 0.1947523374551033, 0.8042550231942229, 0.9973339254533332, 0.4098044212943059, 0.531528506827268, 0.0581570630879708, 0.9961681390243348, 0.9991447201765136, 0.8910248290246232, 0.06698089836745438, 0.041937595120275596, 0.9951957995136876, 0.9927853068544522, 0.9973054646467345, 0.9961844940088486, 0.9962570791463679, 0.9962106047786088, 0.9519713457250817, 0.03917577554424204, 0.008814549497454461, 0.7457126739193664, 0.25356536052899625, 0.9933601954052608, 0.9917234853118215, 0.9950521639087768, 0.997406179338154, 0.9981493999849802, 0.9947633291090343, 0.9919332459473116, 0.4818299151422487, 0.5173565448301565, 0.9963238223125809, 0.9727173341803733, 0.015141926123604814, 0.011507863853939659, 0.9971315351570214, 0.2654067603423275, 0.7141241221075337, 0.020242888500685997, 0.9992493930843024, 0.2282566550245231, 0.7686193485519656, 0.20250535022143526, 0.03430875768214399, 0.7631606586857395, 0.997072395434803, 0.3819226967267148, 0.5609926790747716, 0.04896444829829677, 0.007694413304018064, 0.15103452554366747, 0.848116951129825, 0.9945481362452672, 0.9960855466471843, 0.9959226585247606, 0.9986165601035671, 0.996375842615738, 0.06029591086796384, 0.9326204474468754, 0.006553903355213461, 0.9968125988812716, 0.9525606629451518, 0.04572291182136729, 0.9946355534532226, 0.9985563245588115, 0.6427273237301001, 0.1453122644955009, 0.20762887023107146, 0.004471146599861566, 0.7146254917368047, 0.2846882040252311, 0.9985973983410799, 0.9925079944068737, 0.9899203953721653, 0.9989038257905846, 0.9843739101417786, 0.9947896501106301, 0.9990778112925951, 0.9979343317108764, 0.6058220638230427, 0.3939498666390278, 0.1747576162714521, 0.6664264321993434, 0.03521235551738214, 0.12259116365310818, 0.9961862584152409, 0.41435765934572966, 0.059851661905494284, 0.5263876931688344, 0.280260988405032, 0.7194759702338135, 0.2697055141659196, 0.707824426317798, 0.020746578012763042, 0.9929299361389018, 0.4143965534322416, 0.5846965068975463, 0.995034634285096, 0.9975839639751696, 0.27483164273846006, 0.699293846523415, 0.02595632181418789, 0.9890270903026908, 0.010771582171613463, 0.9984719129101374, 0.21344380911310035, 0.5977799284164321, 0.18873648715788616, 0.15987126961792977, 0.8366596443338324, 0.3246618417978478, 0.675158843420458, 0.3579377430832324, 0.6406784813170462, 0.9936094491675188, 0.9993203358893118, 0.9945399862457501, 0.9966816976431249, 0.198867597250051, 0.03376996934434828, 0.7673287478799137, 0.5717089111664764, 0.3669176594053505, 0.061152943234225085, 0.5126846787152808, 0.34744699605807994, 0.13978023654168345, 0.9958427549262141, 0.9915554887140063, 0.593850863565324, 0.17449453456816713, 0.23143913792374615, 0.989337893170464, 0.03559288835677638, 0.9610079856329623, 0.9938189521433778, 0.6198393765927699, 0.07226370400342638, 0.3083929903244816, 0.9965185209948055, 0.1634317092141409, 0.8363858059782506, 0.5325283772545818, 0.4674770066198904, 0.9969452793109013, 0.998902793696199, 0.3880885252095374, 0.5725896273583339, 0.039329388545824955, 0.9961847591748877, 0.9922646118482223, 0.29142030896304394, 0.7075037500936123, 0.9954224967833283, 0.9955367748480628, 0.9983161280754187, 0.19014424715568828, 0.25470815197347796, 0.5541143918977334, 0.9080433871109159, 0.06687141222909845, 0.024636836084404694, 0.9932174910265631, 0.23748086656168835, 0.761463879479909], \"Term\": [\"amazing\", \"amazing\", \"amazing\", \"ask\", \"ask\", \"atmosphere\", \"attentive\", \"attitude\", \"available\", \"available\", \"available\", \"average\", \"awful\", \"bacon\", \"bad\", \"bad\", \"bagel\", \"bar\", \"bar\", \"bartender\", \"bathroom\", \"bathroom\", \"bbq\", \"be\", \"be\", \"be\", \"be\", \"bean\", \"bed\", \"bed\", \"beef\", \"beer\", \"bill\", \"birthday\", \"boba\", \"bother\", \"bowl\", \"bread\", \"breakfast\", \"breakfast\", \"brunch\", \"butter\", \"cafe\", \"call\", \"call\", \"car\", \"card\", \"care\", \"care\", \"care\", \"casino\", \"charge\", \"cheese\", \"chicken\", \"chocolate\", \"class\", \"clean\", \"clean\", \"clear\", \"clearly\", \"club\", \"club\", \"cocktail\", \"coffee\", \"come\", \"come\", \"come\", \"come\", \"company\", \"company\", \"cookie\", \"cool\", \"cool\", \"cool\", \"cream\", \"crispy\", \"curry\", \"customer\", \"customer\", \"customer\", \"dance\", \"day\", \"day\", \"day\", \"de\", \"decent\", \"decor\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"dessert\", \"dessert\", \"dining\", \"dinner\", \"dinner\", \"dish\", \"dish\", \"doctor\", \"dog\", \"dog\", \"dollar\", \"donut\", \"downtown\", \"dr\", \"drink\", \"drink\", \"eat\", \"eat\", \"efficient\", \"egg\", \"enjoy\", \"enjoy\", \"enjoy\", \"entree\", \"experience\", \"experience\", \"experience\", \"favorite\", \"favorite\", \"feel\", \"feel\", \"feel\", \"feel\", \"find\", \"find\", \"find\", \"find\", \"fish\", \"fish\", \"fix\", \"flavor\", \"floor\", \"floor\", \"food\", \"free\", \"free\", \"free\", \"free\", \"french\", \"fresh\", \"fresh\", \"friend\", \"friend\", \"friend\", \"friendly\", \"friendly\", \"fry\", \"fun\", \"fun\", \"future\", \"garage\", \"gel\", \"get\", \"get\", \"get\", \"get\", \"gift\", \"give\", \"give\", \"give\", \"glad\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"great\", \"great\", \"green\", \"grill\", \"guy\", \"guy\", \"hair\", \"have\", \"have\", \"have\", \"have\", \"heavy\", \"help\", \"help\", \"help\", \"hold\", \"home\", \"home\", \"home\", \"home\", \"honest\", \"horrible\", \"hotel\", \"hour\", \"hour\", \"hurt\", \"ice\", \"ice\", \"indian\", \"issue\", \"japanese\", \"job\", \"know\", \"know\", \"know\", \"knowledgeable\", \"la\", \"lady\", \"lady\", \"later\", \"leave\", \"leave\", \"leave\", \"let\", \"let\", \"light\", \"light\", \"light\", \"like\", \"like\", \"like\", \"like\", \"little\", \"little\", \"little\", \"little\", \"little\", \"locate\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"mac\", \"manager\", \"massage\", \"meal\", \"meal\", \"meat\", \"menu\", \"menu\", \"mexican\", \"milk\", \"minute\", \"minute\", \"modern\", \"money\", \"movie\", \"nail\", \"need\", \"need\", \"need\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"noodle\", \"not\", \"not\", \"not\", \"office\", \"onion\", \"order\", \"order\", \"order\", \"owner\", \"owner\", \"parking\", \"parking\", \"parking\", \"parking\", \"patient\", \"patio\", \"paul\", \"pay\", \"pay\", \"pedicure\", \"people\", \"people\", \"people\", \"phone\", \"pizza\", \"place\", \"place\", \"place\", \"plenty\", \"polish\", \"pool\", \"pork\", \"potato\", \"pour\", \"pretty\", \"pretty\", \"pretty\", \"price\", \"price\", \"pricey\", \"process\", \"product\", \"professional\", \"purchase\", \"raman\", \"realize\", \"recommend\", \"recommend\", \"repair\", \"restaurant\", \"restaurant\", \"restaurant\", \"result\", \"review\", \"review\", \"review\", \"rice\", \"rock\", \"rock\", \"room\", \"room\", \"room\", \"rude\", \"s\", \"s\", \"s\", \"s\", \"salad\", \"salad\", \"salmon\", \"salon\", \"salsa\", \"sauce\", \"save\", \"say\", \"say\", \"say\", \"schedule\", \"seat\", \"seat\", \"send\", \"server\", \"service\", \"service\", \"service\", \"service\", \"shop\", \"shop\", \"shrimp\", \"situation\", \"sorry\", \"soup\", \"spacious\", \"speak\", \"spicy\", \"spot\", \"staff\", \"staff\", \"start\", \"start\", \"start\", \"start\", \"state\", \"stay\", \"stay\", \"stay\", \"steak\", \"steak\", \"store\", \"store\", \"store\", \"strawberry\", \"strip\", \"strip\", \"suite\", \"sushi\", \"sweet\", \"sweet\", \"sweet\", \"table\", \"table\", \"taco\", \"take\", \"take\", \"take\", \"talk\", \"talk\", \"taste\", \"taste\", \"tea\", \"tea\", \"team\", \"tell\", \"tender\", \"thai\", \"thank\", \"thank\", \"thank\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"tire\", \"toronto\", \"try\", \"try\", \"try\", \"typical\", \"update\", \"update\", \"vanilla\", \"vegas\", \"vegas\", \"vegas\", \"veggie\", \"view\", \"view\", \"wait\", \"wait\", \"waiter\", \"waitress\", \"want\", \"want\", \"want\", \"waste\", \"wedding\", \"week\", \"week\", \"wifi\", \"window\", \"wine\", \"work\", \"work\", \"work\", \"worth\", \"worth\", \"worth\", \"wow\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 5, 4, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el54321397981227620648444218515\", ldavis_el54321397981227620648444218515_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el54321397981227620648444218515\", ldavis_el54321397981227620648444218515_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el54321397981227620648444218515\", ldavis_el54321397981227620648444218515_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "\n",
        "# Use a ploting tool of your choice to visualize your results. \n",
        "\n",
        "# YOUR CODE HERE\n",
        "# pyLDAvis.enable_notebook()\n",
        "# visual_plot2 = pyLDAvis.gensim_models.prepare(lda, corpus, id2word)\n",
        "# visual_plot2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visual_plot = plt.figure(figsize = (16,7))\n",
        "visual_plot = plt.gca(xlabel='words')\n",
        "visual_plot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "FpNBqiRbn2vl",
        "outputId": "09eeac0c-a265-4fea-a603-678f01d9f4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f254b727150>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "97e1c557c7e019c69cc2714b055fb767",
          "grade": true,
          "grade_id": "cell-f5fa579a25122b47",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "IvluPdBXvaRF"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert visual_plot.__module__ == 'matplotlib.axes._subplots', \"You must create and assign to visual_plot a visualization\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l16qZeBMnYQB",
        "outputId": "95915c07-2501-45ce-bdcc-c8cdae23831c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural', 'Language', 'Processing', 'is', 'really', 'fun!']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YzsYbhBr-b4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "toc-autonumbering": false,
    "colab": {
      "name": "DS_Unit_4_Sprint_Challenge_1_AG_13.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}