{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNYEFBRxPoJH"
      },
      "source": [
        "BloomTech Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 3*\n",
        "\n",
        "---\n",
        "<p style=\"padding: 10px; border: 2px solid red;\">\n",
        "    <b>Before you start:</b> Today is the day you should submit the dataset for your Unit 2 Build Week project. You can review the guidelines and make your submission in the Build Week course for your cohort on Canvas.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94IX7lsfPoJK"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/main/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install pandas-profiling==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCyQJp7_WE4x",
        "outputId": "572e1a8e-8ab7-46f1-939c-f16efbdb93f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders==2.* in c:\\users\\logan\\anaconda3\\lib\\site-packages (2.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\logan\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\logan\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (1.20.3)\n",
            "Requirement already satisfied: pandas>=0.21.1 in c:\\users\\logan\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (1.3.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\logan\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (0.12.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\logan\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (0.5.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\logan\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (0.24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\logan\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders==2.*) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\logan\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders==2.*) (2021.3)\n",
            "Requirement already satisfied: six in c:\\users\\logan\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders==2.*) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\logan\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (2.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\logan\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders==2.*\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, validation_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOX_DHaGPoJL"
      },
      "source": [
        "# Module Project: Hyperparameter Tuning\n",
        "\n",
        "This sprint, the module projects will focus on creating and improving a model for the Tanazania Water Pump dataset. Your goal is to create a model to predict whether a water pump is functional, non-functional, or needs repair.\n",
        "\n",
        "Dataset source: [DrivenData.org](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/).\n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are as follows:\n",
        "\n",
        "- **Task 1:** Use `wrangle` function to import training and test data.\n",
        "- **Task 2:** Split training data into feature matrix `X` and target vector `y`.\n",
        "- **Task 3:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 4:** Build `clf_dt`.\n",
        "- **Task 5:** Build `clf_rf`.\n",
        "- **Task 6:** Evaluate classifiers using k-fold cross-validation.\n",
        "- **Task 7:** Tune hyperparameters for best performing classifier.\n",
        "- **Task 8:** Print out best score and params for model.\n",
        "- **Task 9:** Create `submission.csv` and upload to Kaggle.\n",
        "\n",
        "You should limit yourself to the following libraries for this project:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `pandas-profiling`\n",
        "- `sklearn`\n",
        "\n",
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpw70CNzPoJL"
      },
      "outputs": [],
      "source": [
        "def wrangle(fm_path, tv_path=None):\n",
        "    if tv_path:\n",
        "        df = pd.merge(pd.read_csv(fm_path, \n",
        "                                  na_values=[0, -2.000000e-08],\n",
        "                      parse_dates = ['date_recorded']),\n",
        "                      pd.read_csv(tv_path)).set_index('id')\n",
        "    else:\n",
        "        df = pd.read_csv(fm_path, \n",
        "                         na_values=[0, -2.000000e-08],\n",
        "                         parse_dates = ['date_recorded'],\n",
        "                         index_col='id')\n",
        "    df['pump_age'] = df['date_recorded'].dt.year - df['construction_year']\n",
        "    df.drop(columns='date_recorded',inplace=True)\n",
        "    # Drop constant columns\n",
        "    df.drop(columns=['recorded_by'], inplace=True)\n",
        "    df.drop(columns=['num_private'], inplace=True)\n",
        "    # Drop HCCCs\n",
        "    cutoff = 100\n",
        "    drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "                 if df[col].nunique() > cutoff]\n",
        "    df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    # Drop duplicate columns\n",
        "    dupe_cols = [col for col in df.head(15).T.duplicated().index\n",
        "                 if df.head(15).T.duplicated()[col]]\n",
        "    df.drop(columns=dupe_cols, inplace=True)             \n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waTGNl2zPoJM"
      },
      "source": [
        "**Task 1:** Using the above `wrangle` function to read `train_features.csv` and `train_labels.csv` into the DataFrame `df`, and `test_features.csv` into the DataFrame `X_test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9ZRirG7PoJM",
        "outputId": "dfc33523-6c21-4918-af73-3d4cef6d7423"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "amount_tsh               33330\n",
              "gps_height               16274\n",
              "longitude                 1433\n",
              "latitude                  1433\n",
              "basin                        0\n",
              "region                       0\n",
              "region_code                  0\n",
              "district_code               19\n",
              "population               17047\n",
              "public_meeting            2688\n",
              "scheme_management         3102\n",
              "permit                    2439\n",
              "construction_year        16502\n",
              "extraction_type              0\n",
              "extraction_type_class        0\n",
              "management                   0\n",
              "management_group             0\n",
              "payment                      0\n",
              "payment_type                 0\n",
              "water_quality                0\n",
              "quality_group                0\n",
              "quantity                     0\n",
              "source                       0\n",
              "source_type                  0\n",
              "source_class                 0\n",
              "waterpoint_type              0\n",
              "status_group                 0\n",
              "pump_age                 16502\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = wrangle(r'C:\\Users\\Logan\\Downloads\\train_features.csv',r'C:\\Users\\Logan\\Downloads\\train_labels.csv')\n",
        "X_test = wrangle(r'C:\\Users\\Logan\\Downloads\\test_features.csv')\n",
        "X_test.drop(columns='waterpoint_type_group',inplace=True)\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zREuJ_OcPoJN"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 2:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'status_group'`.\n",
        "\n",
        "**Note:** You won't need to do a train-test split because you'll use cross-validation instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xx0_zfikPoJN"
      },
      "outputs": [],
      "source": [
        "target = 'status_group'\n",
        "X = df.drop(target,axis=1)\n",
        "y = df[target]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH6qlGX0PoJN"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 3:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1ovVaL1PoJO",
        "outputId": "ec4d88b5-4143-4338-fdd4-dd77b04d4aaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Accuracy Score: 0.5429828068772491\n"
          ]
        }
      ],
      "source": [
        "baseline_acc = y.value_counts(normalize=True).max()\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOwTx5i8PoJP"
      },
      "source": [
        "# IV. Build Models\n",
        "\n",
        "**Task 4:** Build a `Pipeline` named `clf_dt`. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `DecisionTreeClassifier` Predictor.\n",
        "\n",
        "**Note:** Do not train `clf_dt`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at3qXdSSPoJP"
      },
      "outputs": [],
      "source": [
        "clf_dt = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    DecisionTreeClassifier()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_aYtqVgPoJQ"
      },
      "source": [
        "**Task 5:** Build a `Pipeline` named `clf_rf`. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `RandomForestClassifier` predictor.\n",
        "\n",
        "**Note:** Do not train `clf_rf`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GV2y7PxrPoJQ"
      },
      "outputs": [],
      "source": [
        "clf_rf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gAgUXmQPoJQ"
      },
      "source": [
        "# V. Check Metrics\n",
        "\n",
        "**Task 6:** Evaluate the performance of both of your classifiers using k-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AZD3zpTPoJQ"
      },
      "outputs": [],
      "source": [
        "cv_scores_dt = cross_val_score(clf_dt,X,y,cv=5,n_jobs=-1)\n",
        "cv_scores_rf = cross_val_score(clf_rf,X,y,cv=5,n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jv3-NJxPoJQ",
        "outputId": "f33ed818-89da-4901-d5a4-60fbb2f0a8d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV scores DecisionTreeClassifier\n",
            "[0.74347643 0.75126263 0.74926347 0.75126263 0.74408082]\n",
            "Mean CV accuracy score: 0.7478691936198776\n",
            "STD CV accuracy score: 0.003424118441064771\n"
          ]
        }
      ],
      "source": [
        "print('CV scores DecisionTreeClassifier')\n",
        "print(cv_scores_dt)\n",
        "print('Mean CV accuracy score:', cv_scores_dt.mean())\n",
        "print('STD CV accuracy score:', cv_scores_dt.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtCAyd3OPoJR",
        "outputId": "bc8b0df5-6d5c-46d2-bfa1-c25f36a491dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV score RandomForestClassifier\n",
            "[0.79492845 0.79787458 0.7974537  0.80481902 0.79722193]\n",
            "Mean CV accuracy score: 0.7984595374985253\n",
            "STD CV accuracy score: 0.0033405743257382014\n"
          ]
        }
      ],
      "source": [
        "print('CV score RandomForestClassifier')\n",
        "print(cv_scores_rf)\n",
        "print('Mean CV accuracy score:', cv_scores_rf.mean())\n",
        "print('STD CV accuracy score:', cv_scores_rf.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pqNDLe3PoJR"
      },
      "source": [
        "# VI. Tune Model\n",
        "\n",
        "**Task 7:** Choose the best performing of your two models and tune its hyperparameters using a `RandomizedSearchCV` named `model`. Make sure that you include cross-validation and that `n_iter` is set to at least `25`.\n",
        "\n",
        "**Note:** If you're not sure which hyperparameters to tune, check the notes from today's guided project and the `sklearn` documentation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq_UlRhyZ-Lr"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'simpleimputer__strategy':['mean','median'],\n",
        "    'randomforestclassifier__max_depth':range(19,20,1),\n",
        "    'randomforestclassifier__n_estimators':range(195,205,1)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVQhV5puPoJR",
        "outputId": "6e8f5233-3bf3-40a6-d3d5-dc26daa8be11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10,\n",
              "                   estimator=Pipeline(steps=[('ordinalencoder',\n",
              "                                              OrdinalEncoder()),\n",
              "                                             ('simpleimputer', SimpleImputer()),\n",
              "                                             ('randomforestclassifier',\n",
              "                                              RandomForestClassifier())]),\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={'randomforestclassifier__max_depth': range(19, 20),\n",
              "                                        'randomforestclassifier__n_estimators': range(195, 205),\n",
              "                                        'simpleimputer__strategy': ['mean',\n",
              "                                                                    'median']},\n",
              "                   verbose=1)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = RandomizedSearchCV(\n",
        "    clf_rf,\n",
        "    param_distributions = param_grid,\n",
        "    n_jobs= -1,\n",
        "    cv=10,\n",
        "    verbose = 1,\n",
        "    \n",
        ")\n",
        "model.fit(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lFlC8FaPoJR"
      },
      "source": [
        "**Task 8:** Print out the best score and best params for `model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g82PQpTePoJR",
        "outputId": "7487e69f-ee7b-4370-db16-6fe680bb1c16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best score for `model`: 0.8068350885902454\n",
            "Best params for `model`: {'simpleimputer__strategy': 'mean', 'randomforestclassifier__n_estimators': 203, 'randomforestclassifier__max_depth': 19}\n"
          ]
        }
      ],
      "source": [
        "best_score = model.best_score_\n",
        "best_params = model.best_params_\n",
        "\n",
        "print('Best score for `model`:', best_score)\n",
        "print('Best params for `model`:', best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmXr45Y402Sq"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6N-krxqPoJS"
      },
      "source": [
        "# Communicate Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubzPIaQ9PoJS"
      },
      "source": [
        "**Task 9:** Create a DataFrame `submission` whose index is the same as `X_test` and that has one column `'status_group'` with your predictions. Next, save this DataFrame as a CSV file and upload your submissions to our competition site. \n",
        "\n",
        "**Note:** Check the `sample_submission.csv` file on the competition website to make sure your submissions follows the same formatting. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E17nmgSOPoJS"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame(model.predict(X_test))\n",
        "submission.rename({0:'status_group'},axis=1,inplace=True)\n",
        "submission.index = X_test.index\n",
        "submission.to_csv('submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeZ9LaBidm68"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "LS_DS_223_assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}