{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfewp4D11417"
      },
      "source": [
        "BloomTech Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMlEPgLu141-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/main/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install pandas-profiling==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "!pip install category_encoders==2.*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iikgBjFS63Ue",
        "outputId": "dce32614-3df1-410e-8b02-2dcf34a33965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders==2.* in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.21.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (0.5.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders==2.*) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLTmyDnF141_"
      },
      "source": [
        "# Module Project: Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEpprIBg141_"
      },
      "source": [
        "This week, the module projects will focus on creating and improving a model for the Tanazania Water Pump datset. Your goal is to create a model to predict whether a water pump is functional, non-functional, or needs repair.\n",
        "\n",
        "Dataset source: [DrivenData.org](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/).\n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are as follows:\n",
        "\n",
        "- **Task 1:** Sign up for a [Kaggle](https://www.kaggle.com/) account.\n",
        "- **Task 2:** Use `wrangle` function to import training and test data.\n",
        "- **Task 3:** Split training data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
        "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 6:** Build and train `model_dt`.\n",
        "- **Task 7:** Calculate the training and validation accuracy score for your model.\n",
        "- **Task 8:** Adjust model's `max_depth` to reduce overfitting.\n",
        "- **Task 9 `stretch goal`:** Create a horizontal bar chart showing the 10 most important features for your model.\n",
        "\n",
        "You should limit yourself to the following libraries for this project:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `pandas-profiling`\n",
        "- `sklearn`\n",
        "\n",
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkXOVWjD142A"
      },
      "outputs": [],
      "source": [
        "def wrangle(fm_path, tv_path=None):\n",
        "    if tv_path:\n",
        "        df = pd.merge(pd.read_csv(fm_path, \n",
        "                                  na_values=[0, -2.000000e-08],\n",
        "                      parse_dates = ['date_recorded']),\n",
        "                      pd.read_csv(tv_path)).set_index('id')\n",
        "    else:\n",
        "        df = pd.read_csv(fm_path, \n",
        "                         na_values=[0, -2.000000e-08],\n",
        "                         parse_dates = ['date_recorded'],\n",
        "                         index_col='id')\n",
        "    #pump age\n",
        "    df['pump_age'] = df['date_recorded'].dt.year - df['construction_year']\n",
        "    df.drop(columns='date_recorded',inplace=True)\n",
        "    # Drop constant columns\n",
        "    df.drop(columns=['recorded_by'], inplace=True)\n",
        "    df.drop(columns=['num_private'],inplace=True)\n",
        "    # Drop HCCCs\n",
        "    cutoff = 100\n",
        "    drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "                 if df[col].nunique() > cutoff]\n",
        "    df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    #df.dropna(inplace=True)\n",
        "    # Drop duplicate columns\n",
        "    dupe_cols = [col for col in df.head(15).T.duplicated().index\n",
        "                 if df.head(15).T.duplicated()[col]]\n",
        "    df.drop(columns=dupe_cols, inplace=True)            \n",
        "\n",
        "    df.fillna(0,inplace=True)\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiQIwKoR142A"
      },
      "source": [
        "**Task 1:** Sign up for a [Kaggle](https://www.kaggle.com/) account. Choose a username that's based on your real name. Like GitHub, Kaggle is part of your public profile as a data scientist.\n",
        "\n",
        "**Task 2:** Modify the `wrangle` function to engineer a `'pump_age'` feature. Then use the function to read `train_features.csv` and `train_labels.csv` into the DataFrame `df`, and `test_features.csv` into the DataFrame `X_test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSj1_AUr142B",
        "outputId": "a3c3e7ec-6026-406a-e3a8-b71a4ab1ad19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "amount_tsh               0\n",
              "gps_height               0\n",
              "longitude                0\n",
              "latitude                 0\n",
              "basin                    0\n",
              "region                   0\n",
              "region_code              0\n",
              "district_code            0\n",
              "population               0\n",
              "public_meeting           0\n",
              "scheme_management        0\n",
              "permit                   0\n",
              "construction_year        0\n",
              "extraction_type          0\n",
              "extraction_type_class    0\n",
              "management               0\n",
              "management_group         0\n",
              "payment                  0\n",
              "payment_type             0\n",
              "water_quality            0\n",
              "quality_group            0\n",
              "quantity                 0\n",
              "source                   0\n",
              "source_type              0\n",
              "source_class             0\n",
              "waterpoint_type          0\n",
              "status_group             0\n",
              "pump_age                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "df = wrangle('train_features.csv','train_labels.csv')\n",
        "X_test = wrangle('test_features.csv')\n",
        "X_test.drop(columns='waterpoint_type_group',inplace=True)\n",
        "#df.drop(columns = ['status_group'])\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gH1UDTP142B"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'status_group'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN0YJrEk142C"
      },
      "outputs": [],
      "source": [
        "target = 'status_group'\n",
        "X = df.drop(columns=target)\n",
        "y = df[target]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3aS_SGC142C"
      },
      "source": [
        "**Task 4:** Using a randomized split, divide `X` and `y` into a training set (`X_train`, `y_train`) and a validation set (`X_val`, `y_val`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMXgoEOS142C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827027fc-5501-46b4-d827-f981d669262e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47518, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.00001,random_state=42)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPTdAbxL142D"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryfnj-aM142D",
        "outputId": "55a6c724-dea1-4a0a-cd01-6916a077ab0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy Score: functional                 0.542994\n",
            "non functional             0.384086\n",
            "functional needs repair    0.072920\n",
            "Name: status_group, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "baseline_acc = y_train.value_counts(normalize=True)\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhWGw_6P142D"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build a `Pipeline` named `model_rf`, and fit it to your training data. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `RandomForestClassifier` predictor.\n",
        "\n",
        "**Note:** Don't forget to set the `random_state` parameter for your `RandomForestClassifier`. Also, to decrease training time, set `n_jobs` to `-1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUi9Faps142D",
        "outputId": "1151c5fa-329f-488d-b998-db2ae8976b68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['basin', 'region', 'public_meeting',\n",
              "                                      'scheme_management', 'permit',\n",
              "                                      'extraction_type',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'management_group', 'payment',\n",
              "                                      'payment_type', 'water_quality',\n",
              "                                      'quality_group', 'quantity', 'source',\n",
              "                                      'source_type', 'source_class',\n",
              "                                      'waterpoint_type'],\n",
              "                                mapping=[{'col': 'basin',\n",
              "                                          'data_typ...\n",
              "                                          'data_type': dtype('O'),\n",
              "                                          'mapping': groundwater    1\n",
              "surface        2\n",
              "unknown        3\n",
              "NaN           -2\n",
              "dtype: int64},\n",
              "                                         {'col': 'waterpoint_type',\n",
              "                                          'data_type': dtype('O'),\n",
              "                                          'mapping': communal standpipe             1\n",
              "hand pump                      2\n",
              "communal standpipe multiple    3\n",
              "improved spring                4\n",
              "other                          5\n",
              "cattle trough                  6\n",
              "dam                            7\n",
              "NaN                           -2\n",
              "dtype: int64}])),\n",
              "                ('simpleimputer', SimpleImputer()),\n",
              "                ('randomforestclassifier',\n",
              "                 RandomForestClassifier(max_depth=20, n_estimators=200))])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "model_rf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier(n_estimators=200,max_depth=20)\n",
        ")\n",
        "model_rf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLXVqQm9142E"
      },
      "source": [
        "# V. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and validation accuracy scores for `model_rf`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3vbMfS9142E",
        "outputId": "41b03e14-ba0f-4a0d-839c-d532da6a65f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy Score: 0.9441685256113472\n",
            "Validation Accuracy Score: 0.0\n"
          ]
        }
      ],
      "source": [
        "training_acc = model_rf.score(X_train,y_train)\n",
        "val_acc = model_rf.score(X_val,y_val)\n",
        "\n",
        "print('Training Accuracy Score:', training_acc)\n",
        "print('Validation Accuracy Score:', val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR_G1h_g142E"
      },
      "source": [
        "# VI. Tune Model\n",
        "\n",
        "**Task 8:** Tune `n_estimators` and `max_depth` hyperparameters for your `RandomForestClassifier` to get the best validation accuracy score for `model_rf`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnC0lyA4142E"
      },
      "outputs": [],
      "source": [
        "# Use this cell to experiment and then change \n",
        "# your model hyperparameters in Task 6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtuGDIyY142E"
      },
      "source": [
        "# VII. Communicate Results\n",
        "\n",
        "**Task 9:** Generate a list of predictions for `X_test`. The list should be named `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac5v0Et_142F"
      },
      "outputs": [],
      "source": [
        "y_pred = model_rf.predict(X_test)\n",
        "assert len(y_pred) == len(X_test), f'Your list of predictions should have {len(X_test)} items in it. '"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8oA_Wfl142F"
      },
      "source": [
        "**Task 11 `stretch goal`:** Create a DataFrame `submission` whose index is the same as `X_test` and that has one column `'status_group'` with your predictions. Next, save this DataFrame as a CSV file and upload your submissions to our competition site. \n",
        "\n",
        "**Note:** Check the `sample_submission.csv` file on the competition website to make sure your submissions follows the same formatting. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bfp1NPQ142F"
      },
      "outputs": [],
      "source": [
        "y_pred = pd.DataFrame(y_pred)\n",
        "y_pred.index = X_test.index\n",
        "\n",
        "y_pred.rename({0:'status_group'},axis=1,inplace=True)\n",
        "y_pred.to_csv('Submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C5SZcHuuFwaR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "name": "LS_DS_222_assignment.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}