{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfAnutzH_PWR"
      },
      "source": [
        "BloomTech Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0eukO5Ks_PWU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLF73yCu_PWV"
      },
      "source": [
        "# Module Project: Logistic Regression\n",
        "\n",
        "Do you like burritos? ðŸŒ¯ You're in luck then, because in this project you'll create a model to predict whether a burrito is `'Great'`.\n",
        "\n",
        "The dataset for this assignment comes from [Scott Cole](https://srcole.github.io/100burritos/), a San Diego-based data scientist and burrito enthusiast. \n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are the following:\n",
        "\n",
        "- **Task 1:** Import `csv` file using `wrangle` function.\n",
        "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function .\n",
        "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
        "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 6:** Build `model_logr` using a pipeline that includes three transfomers and `LogisticRegression` predictor. Train model on `X_train` and `X_test`.\n",
        "- **Task 7:** Calculate the training and test accuracy score for your model.\n",
        "- **Task 8:** Create a horizontal bar chart showing the 10 most influencial features for your  model. \n",
        "- **Task 9:** Demonstrate and explain the differences between `model_lr.predict()` and `model_lr.predict_proba()`.\n",
        "\n",
        "**Note** \n",
        "\n",
        "You should limit yourself to the following libraries:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `sklearn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RmMA7sI_PWV"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "799B6Sdi_PWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb65f9e-969a-41db-e7f2-16ffb19f66c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: category_encoders==2.* in /usr/local/lib/python3.8/dist-packages (2.5.1.post0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (1.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (1.3.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (1.7.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders==2.*) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders==2.*) (2022.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.1->category_encoders==2.*) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "def wrangle(filepath):\n",
        "    # Import w/ DateTimeIndex\n",
        "    df = pd.read_csv(filepath, parse_dates=['Date'],\n",
        "                     index_col='Date')\n",
        "    \n",
        "    # Drop unrated burritos\n",
        "    df.dropna(subset=['overall'], inplace=True)\n",
        "    \n",
        "    # Derive binary classification target:\n",
        "    # We define a 'Great' burrito as having an\n",
        "    # overall rating of 4 or higher, on a 5 point scale\n",
        "    df['Great'] = (df['overall'] >= 4).astype(int)\n",
        "    \n",
        "    # Drop high cardinality categoricals\n",
        "    df = df.drop(columns=['Notes', 'Location', 'Address', 'URL', 'Neighborhood'])\n",
        "    \n",
        "    # Drop columns to prevent \"leakage\"\n",
        "    df = df.drop(columns=['Rec', 'overall'])\n",
        "\n",
        "    df.fillna(0, inplace= True)\n",
        "    df.replace(to_replace=['X','x'],value= 1,inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "filepath = DATA_PATH + 'burritos/burritos.csv'\n",
        "!pip install category_encoders==2.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import numpy as np\n",
        "!pip install category_encoders==2.*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPwK3jHPVUhe",
        "outputId": "ab1ae857-728e-4616-f16a-e4117c78b3d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: category_encoders==2.* in /usr/local/lib/python3.8/dist-packages (2.5.1.post0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (1.3.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (0.12.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (1.0.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders==2.*) (1.7.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders==2.*) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders==2.*) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.1->category_encoders==2.*) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFM1WoE7_PWW"
      },
      "source": [
        "**Task 1:** Use the above `wrangle` function to import the `burritos.csv` file into a DataFrame named `df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "0ZICzET__PWX",
        "outputId": "f6b4edb2-4bea-4e6c-ceb1-cb4761ffad66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Burrito  Yelp  Google Chips  Cost  Hunger  Mass (g)  \\\n",
              "Date                                                                  \n",
              "2016-01-18  California    3.5     4.2     0  6.49     3.0       0.0   \n",
              "2016-01-24  California    3.5     3.3     0  5.45     3.5       0.0   \n",
              "2016-01-24     Carnitas   0.0     0.0     0  4.85     1.5       0.0   \n",
              "2016-01-24  Carne asada   0.0     0.0     0  5.25     2.0       0.0   \n",
              "2016-01-27   California   4.0     3.8     1  6.59     4.0       0.0   \n",
              "\n",
              "            Density (g/mL)  Length  Circum  ...  Lobster  Queso  Egg  \\\n",
              "Date                                        ...                        \n",
              "2016-01-18             0.0     0.0     0.0  ...        0    0.0    0   \n",
              "2016-01-24             0.0     0.0     0.0  ...        0    0.0    0   \n",
              "2016-01-24             0.0     0.0     0.0  ...        0    0.0    0   \n",
              "2016-01-24             0.0     0.0     0.0  ...        0    0.0    0   \n",
              "2016-01-27             0.0     0.0     0.0  ...        0    0.0    0   \n",
              "\n",
              "            Mushroom  Bacon  Sushi  Avocado  Corn  Zucchini  Great  \n",
              "Date                                                                \n",
              "2016-01-18         0      0      0        0     0         0      0  \n",
              "2016-01-24         0      0      0        0     0         0      0  \n",
              "2016-01-24         0      0      0        0     0         0      0  \n",
              "2016-01-24         0      0      0        0     0         0      0  \n",
              "2016-01-27         0      0      0        0     0         0      1  \n",
              "\n",
              "[5 rows x 59 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c661dd73-8bc1-4755-a273-a12ce48e6bac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>...</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-18</th>\n",
              "      <td>California</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>California</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Carne asada</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-27</th>\n",
              "      <td>California</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 59 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c661dd73-8bc1-4755-a273-a12ce48e6bac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c661dd73-8bc1-4755-a273-a12ce48e6bac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c661dd73-8bc1-4755-a273-a12ce48e6bac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "filepath = DATA_PATH + 'burritos/burritos.csv'\n",
        "df = wrangle(filepath)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD2I1xdqVx4x",
        "outputId": "72d0fb21-b0a8-4f8e-d716-4f0c323c7bc0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(421, 59)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBVtEyHb_PWX"
      },
      "source": [
        "During your exploratory data analysis, note that there are several columns whose data type is `object` but that seem to be a binary encoding. For example, `df['Beef'].head()` returns:\n",
        "\n",
        "```\n",
        "0      x\n",
        "1      x\n",
        "2    NaN\n",
        "3      x\n",
        "4      x\n",
        "Name: Beef, dtype: object\n",
        "```\n",
        "\n",
        "**Task 2:** Change the `wrangle` function so that these columns are properly encoded as `0` and `1`s. Be sure your code handles upper- and lowercase `X`s, and `NaN`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xAvZvpaR_PWY"
      },
      "outputs": [],
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "1XLU-STcfpLp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr-Ymz5a_PWY"
      },
      "source": [
        "If you explore the `'Burrito'` column of `df`, you'll notice that it's a high-cardinality categorical feature. You'll also notice that there's a lot of overlap between the categories. \n",
        "\n",
        "**Stretch Goal:** Change the `wrangle` function above so that it engineers four new features: `'california'`, `'asada'`, `'surf'`, and `'carnitas'`. Each row should have a `1` or `0` based on the text information in the `'Burrito'` column. For example, here's how the first 5 rows of the dataset would look.\n",
        "\n",
        "| **Burrito** | **california** | **asada** | **surf** | **carnitas** |\n",
        "| :---------- | :------------: | :-------: | :------: | :----------: |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "|  Carnitas   |       0        |     0     |    0     |      1       |\n",
        "| Carne asada |       0        |     1     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "\n",
        "**Note:** Be sure to also drop the `'Burrito'` once you've engineered your new features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uUiTEvJ7_PWY"
      },
      "outputs": [],
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S47ryMxJ_PWZ"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your dataset into the feature matrix `X` and the target vector `y`. You want to predict `'Great'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JPpHki1a_PWZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "outputId": "b847804f-cec5-46b4-8797-bf074b8a9bb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Burrito  Yelp  Google Chips  Cost  Hunger  Mass (g)  \\\n",
              "Date                                                                    \n",
              "2016-01-18    California    3.5     4.2     0  6.49     3.0       0.0   \n",
              "2016-01-24    California    3.5     3.3     0  5.45     3.5       0.0   \n",
              "2016-01-24       Carnitas   0.0     0.0     0  4.85     1.5       0.0   \n",
              "2016-01-24    Carne asada   0.0     0.0     0  5.25     2.0       0.0   \n",
              "2016-01-27     California   4.0     3.8     1  6.59     4.0       0.0   \n",
              "...                   ...   ...     ...   ...   ...     ...       ...   \n",
              "2019-08-27      Al Pastor   0.0     0.0     0  6.00     1.0       0.0   \n",
              "2019-08-27  Chile Relleno   0.0     0.0     0  6.00     4.0       0.0   \n",
              "2019-08-27     California   0.0     0.0     0  7.90     3.0       0.0   \n",
              "2019-08-27         Shrimp   0.0     0.0     0  7.90     3.0       0.0   \n",
              "2019-08-27    Pollo Asado   0.0     0.0     0  5.50     3.5       0.0   \n",
              "\n",
              "            Density (g/mL)  Length  Circum  ...  Nopales  Lobster  Queso  Egg  \\\n",
              "Date                                        ...                                 \n",
              "2016-01-18             0.0     0.0     0.0  ...        0        0    0.0    0   \n",
              "2016-01-24             0.0     0.0     0.0  ...        0        0    0.0    0   \n",
              "2016-01-24             0.0     0.0     0.0  ...        0        0    0.0    0   \n",
              "2016-01-24             0.0     0.0     0.0  ...        0        0    0.0    0   \n",
              "2016-01-27             0.0     0.0     0.0  ...        0        0    0.0    0   \n",
              "...                    ...     ...     ...  ...      ...      ...    ...  ...   \n",
              "2019-08-27             0.0    17.0    20.5  ...        0        0    0.0    0   \n",
              "2019-08-27             0.0    19.0    26.0  ...        0        0    0.0    0   \n",
              "2019-08-27             0.0    20.0    22.0  ...        0        0    0.0    0   \n",
              "2019-08-27             0.0    22.5    24.5  ...        0        0    0.0    0   \n",
              "2019-08-27             0.0    17.0    21.3  ...        0        0    0.0    0   \n",
              "\n",
              "            Mushroom  Bacon  Sushi  Avocado  Corn  Zucchini  \n",
              "Date                                                         \n",
              "2016-01-18         0      0      0        0     0         0  \n",
              "2016-01-24         0      0      0        0     0         0  \n",
              "2016-01-24         0      0      0        0     0         0  \n",
              "2016-01-24         0      0      0        0     0         0  \n",
              "2016-01-27         0      0      0        0     0         0  \n",
              "...              ...    ...    ...      ...   ...       ...  \n",
              "2019-08-27         0      0      0        0     0         0  \n",
              "2019-08-27         0      0      0        0     0         0  \n",
              "2019-08-27         0      0      0        0     0         0  \n",
              "2019-08-27         0      0      0        0     0         0  \n",
              "2019-08-27         0      0      0        0     0         0  \n",
              "\n",
              "[421 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-223113e7-f942-4384-87ff-f445de9019fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>...</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-18</th>\n",
              "      <td>California</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>California</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Carne asada</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-27</th>\n",
              "      <td>California</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-27</th>\n",
              "      <td>Al Pastor</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>20.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-27</th>\n",
              "      <td>Chile Relleno</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-27</th>\n",
              "      <td>California</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.90</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-27</th>\n",
              "      <td>Shrimp</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.90</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>24.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-27</th>\n",
              "      <td>Pollo Asado</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>21.3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>421 rows Ã— 58 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-223113e7-f942-4384-87ff-f445de9019fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-223113e7-f942-4384-87ff-f445de9019fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-223113e7-f942-4384-87ff-f445de9019fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "y = df['Great']\n",
        "X = df.drop(columns='Great')\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LkfwwyP_p88",
        "outputId": "33aaf11c-286b-4e65-e1c4-8270b58bd403"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2016-01-18', '2016-01-24', '2016-01-24', '2016-01-24',\n",
              "               '2016-01-27', '2016-01-28', '2016-01-30', '2016-01-30',\n",
              "               '2016-02-01', '2016-02-06',\n",
              "               ...\n",
              "               '2019-08-24', '2019-08-27', '2019-08-27', '2019-08-27',\n",
              "               '2019-08-27', '2019-08-27', '2019-08-27', '2019-08-27',\n",
              "               '2019-08-27', '2019-08-27'],\n",
              "              dtype='datetime64[ns]', name='Date', length=421, freq=None)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9NG7Mudi_s02"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlJPJkEt_PWZ"
      },
      "source": [
        "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
        "\n",
        "- Your training set should include data from 2016 through 2017. \n",
        "- Your test set should include data from 2018 and later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0oXjn821_PWZ"
      },
      "outputs": [],
      "source": [
        "mask = df.index < '2017-01-01'\n",
        "X_train = X.loc[mask]\n",
        "y_train = y.loc[mask]\n",
        "X_test = X.loc[~mask]\n",
        "y_test = y.loc[~mask]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtKwaDY-_PWa"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTg35ek5_PWa",
        "outputId": "59846d95-3518-42af-ecab-62fe9893bfb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy Score: 69.31818181818183\n"
          ]
        }
      ],
      "source": [
        "#y_train.value_counts()[0]\n",
        "baseline_acc = y_train.value_counts()[1] / y_train.value_counts()[0]\n",
        "print('Baseline Accuracy Score:', baseline_acc*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWKl-y_r_PWa"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build a `Pipeline` named `model_logr`, and fit it to your training data. Your pipeline should include:\n",
        "\n",
        "- a `OneHotEncoder` transformer for categorical features, \n",
        "- a `SimpleImputer` transformer to deal with missing values, \n",
        "- a [`StandarScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) transfomer (which often improves performance in a logistic regression model), and \n",
        "- a `LogisticRegression` predictor."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QjP-S9O4Dad4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EPCfzRdx_PWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37fd744d-6855-4ab9-dd7c-b68cbc14fa42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('onehotencoder',\n",
              "                 OneHotEncoder(cols=['Burrito', 'Chips', 'Reviewer'],\n",
              "                               use_cat_names=True)),\n",
              "                ('simpleimputer', SimpleImputer()),\n",
              "                ('standardscaler', StandardScaler()),\n",
              "                ('logisticregression', LogisticRegression())])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from category_encoders import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "model_logr = make_pipeline(\n",
        "    OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression()\n",
        ")\n",
        "model_logr.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHhFrrKh_PWa"
      },
      "source": [
        "# IV. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and test accuracy score for `model_lr`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdfBINVe_PWb",
        "outputId": "9f041db4-bcc1-4850-f32a-8723704c5a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MAE: 1.0\n",
            "Test MAE: 0.7642276422764228\n"
          ]
        }
      ],
      "source": [
        "training_acc = model_logr.score(X_train,y_train)\n",
        "test_acc = model_logr.score(X_test,y_test)\n",
        "\n",
        "print('Training MAE:', training_acc)\n",
        "print('Test MAE:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBNgftXE_PWb"
      },
      "source": [
        "# V. Communicate Results\n",
        "\n",
        "**Task 8:** Create a horizontal barchart that plots the 10 most important coefficients for `model_lr`, sorted by absolute value.\n",
        "\n",
        "**Note:** Since you created your model using a `Pipeline`, you'll need to use the [`named_steps`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) attribute to access the coefficients in your `LogisticRegression` predictor. Be sure to look at the shape of the coefficients array before you combine it with the feature names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "N1qbETkB_PWb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "cdf46ce0-0653-451e-d4bf-b85b78beed3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e41537970>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Create your horizontal barchart here.\n",
        "coefficients = model_logr.named_steps['logisticregression'].coef_[0]\n",
        "features = model_logr.named_steps['onehotencoder'].get_feature_names()\n",
        "feat_imp = pd.Series(coefficients,index=features).sort_values(key=abs)\n",
        "feat_imp.tail(10).plot(kind='barh')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpnwVDPQ_PWb"
      },
      "source": [
        "There is more than one way to generate predictions with `model_lr`. For instance, you can use [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression) or [`predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression.predict_proba).\n",
        "\n",
        "**Task 9:** Generate predictions for `X_test` using both `predict` and `predict_proba`. Then below, write a summary of the differences in the output for these two methods. You should answer the following questions:\n",
        "\n",
        "- What data type do `predict` and `predict_proba` output?\n",
        "- What are the shapes of their different output?\n",
        "- What numerical values are in the output?\n",
        "- What do those numerical values represent?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1R0fWS4n_PWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ea0de3-a045-4e23-b15e-53f7c78b63a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0\n",
            " 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1\n",
            " 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 1 1 1 0\n",
            " 0 1 1 1 0 1 1 0 0 1 1 1]\n",
            "[[1.79345273e-04 9.99820655e-01]\n",
            " [2.23274389e-01 7.76725611e-01]\n",
            " [9.99173415e-01 8.26584646e-04]\n",
            " [1.49220119e-02 9.85077988e-01]\n",
            " [1.79177523e-01 8.20822477e-01]\n",
            " [9.99999755e-01 2.45403456e-07]\n",
            " [9.04059577e-01 9.59404227e-02]\n",
            " [1.91753409e-02 9.80824659e-01]\n",
            " [3.17560019e-02 9.68243998e-01]\n",
            " [9.99077822e-01 9.22177846e-04]\n",
            " [4.63100832e-03 9.95368992e-01]\n",
            " [4.07647115e-03 9.95923529e-01]\n",
            " [9.99875214e-01 1.24785736e-04]\n",
            " [6.03461107e-01 3.96538893e-01]\n",
            " [4.74028792e-01 5.25971208e-01]\n",
            " [1.90384021e-05 9.99980962e-01]\n",
            " [8.15484839e-01 1.84515161e-01]\n",
            " [1.56907236e-01 8.43092764e-01]\n",
            " [5.26695290e-02 9.47330471e-01]\n",
            " [3.59320725e-02 9.64067927e-01]\n",
            " [4.83525871e-06 9.99995165e-01]\n",
            " [2.12897771e-02 9.78710223e-01]\n",
            " [2.13530841e-01 7.86469159e-01]\n",
            " [9.78389789e-01 2.16102114e-02]\n",
            " [5.16695317e-01 4.83304683e-01]\n",
            " [4.32748990e-02 9.56725101e-01]\n",
            " [3.20024403e-02 9.67997560e-01]\n",
            " [4.99499073e-03 9.95005009e-01]\n",
            " [3.78521932e-02 9.62147807e-01]\n",
            " [1.84698401e-01 8.15301599e-01]\n",
            " [9.89699460e-01 1.03005399e-02]\n",
            " [3.36159967e-02 9.66384003e-01]\n",
            " [6.67828758e-01 3.32171242e-01]\n",
            " [8.88582200e-01 1.11417800e-01]\n",
            " [9.53245306e-01 4.67546943e-02]\n",
            " [8.61446446e-01 1.38553554e-01]\n",
            " [6.77166025e-01 3.22833975e-01]\n",
            " [5.46562315e-01 4.53437685e-01]\n",
            " [1.24950072e-02 9.87504993e-01]\n",
            " [9.81514152e-01 1.84858477e-02]\n",
            " [9.55002556e-01 4.49974444e-02]\n",
            " [8.54374024e-01 1.45625976e-01]\n",
            " [1.52131190e-01 8.47868810e-01]\n",
            " [1.49516883e-01 8.50483117e-01]\n",
            " [2.14032956e-04 9.99785967e-01]\n",
            " [1.93523505e-02 9.80647649e-01]\n",
            " [5.22197664e-02 9.47780234e-01]\n",
            " [9.97360698e-01 2.63930185e-03]\n",
            " [9.88640671e-01 1.13593290e-02]\n",
            " [5.92819932e-01 4.07180068e-01]\n",
            " [9.99990340e-01 9.66030932e-06]\n",
            " [9.68308505e-01 3.16914945e-02]\n",
            " [4.72910891e-01 5.27089109e-01]\n",
            " [1.30877725e-02 9.86912228e-01]\n",
            " [4.19320952e-02 9.58067905e-01]\n",
            " [4.29410853e-01 5.70589147e-01]\n",
            " [9.84625664e-01 1.53743361e-02]\n",
            " [8.29855675e-01 1.70144325e-01]\n",
            " [9.46474343e-01 5.35256567e-02]\n",
            " [5.57522670e-01 4.42477330e-01]\n",
            " [9.99325649e-01 6.74350582e-04]\n",
            " [9.99996392e-01 3.60766329e-06]\n",
            " [9.19127166e-01 8.08728343e-02]\n",
            " [9.99993076e-01 6.92417849e-06]\n",
            " [7.58292514e-01 2.41707486e-01]\n",
            " [4.03660142e-01 5.96339858e-01]\n",
            " [3.93746760e-03 9.96062532e-01]\n",
            " [6.09856539e-01 3.90143461e-01]\n",
            " [7.23305253e-05 9.99927669e-01]\n",
            " [6.43710320e-02 9.35628968e-01]\n",
            " [6.67679039e-01 3.32320961e-01]\n",
            " [7.50905361e-05 9.99924909e-01]\n",
            " [1.23330716e-03 9.98766693e-01]\n",
            " [3.37279537e-02 9.66272046e-01]\n",
            " [2.22084309e-02 9.77791569e-01]\n",
            " [9.99828534e-01 1.71465586e-04]\n",
            " [7.69879276e-01 2.30120724e-01]\n",
            " [9.86157446e-01 1.38425537e-02]\n",
            " [2.32307988e-02 9.76769201e-01]\n",
            " [1.38090121e-02 9.86190988e-01]\n",
            " [2.43349317e-03 9.97566507e-01]\n",
            " [2.36924591e-01 7.63075409e-01]\n",
            " [6.88050486e-02 9.31194951e-01]\n",
            " [8.75819068e-01 1.24180932e-01]\n",
            " [9.32036456e-02 9.06796354e-01]\n",
            " [2.64487798e-05 9.99973551e-01]\n",
            " [3.47909255e-04 9.99652091e-01]\n",
            " [8.38307794e-01 1.61692206e-01]\n",
            " [5.54532323e-07 9.99999445e-01]\n",
            " [9.75257453e-01 2.47425473e-02]\n",
            " [9.37054891e-01 6.29451091e-02]\n",
            " [1.01879346e-01 8.98120654e-01]\n",
            " [7.84318144e-04 9.99215682e-01]\n",
            " [5.50779433e-03 9.94492206e-01]\n",
            " [1.31096860e-01 8.68903140e-01]\n",
            " [8.40648146e-01 1.59351854e-01]\n",
            " [9.63463172e-01 3.65368280e-02]\n",
            " [1.18925877e-01 8.81074123e-01]\n",
            " [5.54978993e-01 4.45021007e-01]\n",
            " [6.09087721e-02 9.39091228e-01]\n",
            " [1.40348164e-02 9.85965184e-01]\n",
            " [5.93247721e-02 9.40675228e-01]\n",
            " [9.80862757e-01 1.91372428e-02]\n",
            " [9.71625700e-01 2.83743004e-02]\n",
            " [9.80554419e-01 1.94455811e-02]\n",
            " [9.83564575e-01 1.64354251e-02]\n",
            " [2.10658582e-02 9.78934142e-01]\n",
            " [1.40368329e-01 8.59631671e-01]\n",
            " [8.50194356e-04 9.99149806e-01]\n",
            " [2.35087908e-01 7.64912092e-01]\n",
            " [9.12667391e-01 8.73326091e-02]\n",
            " [9.99998472e-01 1.52780890e-06]\n",
            " [4.01371459e-06 9.99995986e-01]\n",
            " [9.80691926e-03 9.90193081e-01]\n",
            " [1.91762285e-03 9.98082377e-01]\n",
            " [9.53202510e-01 4.67974898e-02]\n",
            " [2.94013307e-02 9.70598669e-01]\n",
            " [1.76890380e-03 9.98231096e-01]\n",
            " [9.98352038e-01 1.64796206e-03]\n",
            " [8.76248494e-01 1.23751506e-01]\n",
            " [4.42091397e-02 9.55790860e-01]\n",
            " [3.88053948e-04 9.99611946e-01]\n",
            " [7.47863838e-03 9.92521362e-01]]\n"
          ]
        }
      ],
      "source": [
        "# Write code here to explore the differences between `predict` and `predict_proba`.\n",
        "print(model_logr.predict(X_test))\n",
        "print(model_logr.predict_proba(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK9viarW_PWb"
      },
      "source": [
        "**Give your written answer here:**\n",
        "\n",
        "```\n",
        "Both methods output a ndarray\n",
        "\n",
        "The shape of predict is (123,) and the shape of the preditc proba is (123,2)\n",
        "\n",
        "The numerical values in the predict method are the more likely option for the outcome while the numerical outut for proba is the likelihood of that outcome\n",
        "\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "LS_DS_214_assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}